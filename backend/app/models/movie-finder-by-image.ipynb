{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-10T11:14:24.337942Z",
     "iopub.status.busy": "2025-05-10T11:14:24.337718Z",
     "iopub.status.idle": "2025-05-10T11:16:58.916126Z",
     "shell.execute_reply": "2025-05-10T11:16:58.915462Z",
     "shell.execute_reply.started": "2025-05-10T11:14:24.337919Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-10T13:06:54.531291Z",
     "iopub.status.busy": "2025-05-10T13:06:54.530726Z",
     "iopub.status.idle": "2025-05-10T13:07:19.110663Z",
     "shell.execute_reply": "2025-05-10T13:07:19.109999Z",
     "shell.execute_reply.started": "2025-05-10T13:06:54.531267Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q faiss-cpu\n",
    "!pip install -q tensorflow==2.18.0\n",
    "!pip install -q skl2onnx onnx onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:07:24.198077Z",
     "iopub.status.busy": "2025-05-10T13:07:24.197369Z",
     "iopub.status.idle": "2025-05-10T13:07:37.694540Z",
     "shell.execute_reply": "2025-05-10T13:07:37.693790Z",
     "shell.execute_reply.started": "2025-05-10T13:07:24.198041Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# Ki·ªÉm tra phi√™n b·∫£n TensorFlow\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# C·∫•u h√¨nh memory growth ƒë·ªÉ s·ª≠ d·ª•ng GPU hi·ªáu qu·∫£\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"T√¨m th·∫•y {len(gpus)} GPU:\")\n",
    "    for i, gpu in enumerate(gpus):\n",
    "        print(f\"  GPU {i}: {gpu}\")\n",
    "    \n",
    "    # C·∫•u h√¨nh memory growth\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        \n",
    "        # M·ªôt s·ªë t√πy ch·ªçn ƒë·ªÉ t·ªëi ∆∞u hi·ªáu su·∫•t cho GPU T4\n",
    "        os.environ['TF_GPU_THREAD_MODE'] = 'gpu_private'\n",
    "        os.environ['TF_GPU_THREAD_COUNT'] = '2'  # T∆∞∆°ng ·ª©ng v·ªõi s·ªë GPU\n",
    "        \n",
    "        # Hi·ªÉn th·ªã c√°c GPU logic\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(f\"S·ªë l∆∞·ª£ng GPU v·∫≠t l√Ω: {len(gpus)}, s·ªë l∆∞·ª£ng GPU logic: {len(logical_gpus)}\")\n",
    "        \n",
    "        # Th√¥ng tin chi ti·∫øt v·ªÅ GPU\n",
    "        from tensorflow.python.client import device_lib\n",
    "        local_device_protos = device_lib.list_local_devices()\n",
    "        gpu_list = [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "        print(f\"Danh s√°ch GPU: {gpu_list}\")\n",
    "        \n",
    "        # Hi·ªÉn th·ªã th√¥ng tin CUDA v√† cuDNN\n",
    "        build_info = tf.sysconfig.get_build_info()\n",
    "        print(f\"CUDA version: {build_info.get('cuda_version', 'N/A')}\")\n",
    "        print(f\"cuDNN version: {build_info.get('cudnn_version', 'N/A')}\")\n",
    "        \n",
    "        # Ki·ªÉm tra xem GPU c√≥ th·ª±c s·ª± ƒë∆∞·ª£c s·ª≠ d·ª•ng hay kh√¥ng\n",
    "        print(\"\\nX√°c nh·∫≠n GPU ƒëang ho·∫°t ƒë·ªông b·∫±ng ph√©p t√≠nh nh·ªè:\")\n",
    "        with tf.device('/GPU:0'):\n",
    "            a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "            b = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
    "            c = tf.matmul(a, b)\n",
    "            print(f\"T√≠nh to√°n tr√™n GPU: {c}\")\n",
    "            print(f\"ƒêang ch·∫°y tr√™n thi·∫øt b·ªã: {c.device}\")\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        print(f\"L·ªói khi c·∫•u h√¨nh GPU: {e}\")\n",
    "else:\n",
    "    print(\"Kh√¥ng t√¨m th·∫•y GPU! ƒêang s·ª≠ d·ª•ng CPU.\")\n",
    "    \n",
    "    # Ki·ªÉm tra th√¥ng tin CPU\n",
    "    cpu_devices = tf.config.list_physical_devices('CPU')\n",
    "    print(f\"T√¨m th·∫•y {len(cpu_devices)} CPU: {cpu_devices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:07:39.717217Z",
     "iopub.status.busy": "2025-05-10T13:07:39.716717Z",
     "iopub.status.idle": "2025-05-10T13:07:41.728132Z",
     "shell.execute_reply": "2025-05-10T13:07:41.727500Z",
     "shell.execute_reply.started": "2025-05-10T13:07:39.717195Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version 2.18.0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import warnings\n",
    "import gc\n",
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm \n",
    "import shutil\n",
    "\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Input, Conv2D, Flatten, Dropout, AveragePooling2D, GlobalAveragePooling2D, UpSampling2D, Resizing\n",
    "from tensorflow.keras.layers import MaxPooling2D, Activation, BatchNormalization, Attention, Reshape, RepeatVector, Lambda, Conv2DTranspose\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "import joblib\n",
    "\n",
    "import onnxruntime as ort\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "# B·ªè qua c√°c c·∫£nh b√°o\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# In phi√™n b·∫£n TensorFlow hi·ªán t·∫°i\n",
    "print('TensorFlow Version ' + tf.__version__)\n",
    "\n",
    "def seed_everything(seed=0):\n",
    "    # Thi·∫øt l·∫≠p seed ƒë·ªÉ ƒë·∫£m b·∫£o t√≠nh t√°i l·∫≠p (reproducibility)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "# G·ªçi h√†m seed_everything ƒë·ªÉ thi·∫øt l·∫≠p seed m·∫∑c ƒë·ªãnh\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tr·ª±c quan d·ªØ li·ªáu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T11:23:26.807364Z",
     "iopub.status.busy": "2025-05-10T11:23:26.806818Z",
     "iopub.status.idle": "2025-05-10T11:24:34.105943Z",
     "shell.execute_reply": "2025-05-10T11:24:34.105351Z",
     "shell.execute_reply.started": "2025-05-10T11:23:26.807331Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Th∆∞ m·ª•c Train====\n",
      "==> T·ªïng s·ªë ·∫£nh: 39833\n",
      "====Th∆∞ m·ª•c Test====\n",
      "==> T·ªïng s·ªë ·∫£nh: 33766\n"
     ]
    }
   ],
   "source": [
    "def count_images_per_folder(root_dir, image_extensions=None):\n",
    "    if image_extensions is None:\n",
    "        image_extensions = ['.jpg']\n",
    "\n",
    "    total = 0\n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        count = sum(1 for file in files if any(file.lower().endswith(ext) for ext in image_extensions))\n",
    "        if count > 0:\n",
    "            relative_path = os.path.relpath(subdir, root_dir)\n",
    "            # print(f\"Th∆∞ m·ª•c '{relative_path}': {count} ·∫£nh\")\n",
    "            total += count\n",
    "\n",
    "    print(f\"==> T·ªïng s·ªë ·∫£nh: {total}\")\n",
    "\n",
    "print(\"====Th∆∞ m·ª•c Train====\")\n",
    "folder_train_path = '/kaggle/input/frames-film-vietnam-dataset/Frame_Train'\n",
    "count_images_per_folder(folder_train_path)\n",
    "\n",
    "print(\"====Th∆∞ m·ª•c Test====\")\n",
    "folder_test_path = '/kaggle/input/frames-film-vietnam-dataset/Frame_Test'\n",
    "count_images_per_folder(folder_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T11:24:39.432764Z",
     "iopub.status.busy": "2025-05-10T11:24:39.432172Z",
     "iopub.status.idle": "2025-05-10T11:24:54.927176Z",
     "shell.execute_reply": "2025-05-10T11:24:54.926525Z",
     "shell.execute_reply.started": "2025-05-10T11:24:39.432739Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def count_images_per_folder(root_dir, image_extensions=None):\n",
    "    if image_extensions is None:\n",
    "        image_extensions = ['.jpg']\n",
    "\n",
    "    folder_counts = {}\n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        if subdir == root_dir:\n",
    "            continue  # b·ªè qua th∆∞ m·ª•c g·ªëc\n",
    "        count = sum(1 for file in files if any(file.lower().endswith(ext) for ext in image_extensions))\n",
    "        if count > 0:\n",
    "            folder_name = os.path.basename(subdir)\n",
    "            folder_counts[folder_name] = count\n",
    "\n",
    "    return folder_counts\n",
    "\n",
    "def plot_image_counts(folder_counts):\n",
    "    folders = list(folder_counts.keys())\n",
    "    counts = list(folder_counts.values())\n",
    "\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    plt.bar(folders, counts, color='skyblue')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel('T√™n th∆∞ m·ª•c con')\n",
    "    plt.ylabel('S·ªë l∆∞·ª£ng ·∫£nh')\n",
    "    plt.title('S·ªë l∆∞·ª£ng ·∫£nh trong t·ª´ng th∆∞ m·ª•c con')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# T·∫≠p Train\n",
    "counts = count_images_per_folder(folder_train_path)\n",
    "plot_image_counts(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T03:58:17.026956Z",
     "iopub.status.busy": "2025-05-10T03:58:17.026136Z",
     "iopub.status.idle": "2025-05-10T03:58:30.128570Z",
     "shell.execute_reply": "2025-05-10T03:58:30.127791Z",
     "shell.execute_reply.started": "2025-05-10T03:58:17.026926Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# T·∫≠p Test\n",
    "counts = count_images_per_folder(folder_test_path)\n",
    "plot_image_counts(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T·∫°o t·∫≠p d·ªØ li·ªáu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:08:03.149034Z",
     "iopub.status.busy": "2025-05-10T13:08:03.148440Z",
     "iopub.status.idle": "2025-05-10T13:08:03.154296Z",
     "shell.execute_reply": "2025-05-10T13:08:03.153530Z",
     "shell.execute_reply.started": "2025-05-10T13:08:03.149009Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_size = 128\n",
    "n_classes = 42\n",
    "batch_size = 128\n",
    "\n",
    "classes = {\n",
    "    1: \"21_Ngay_Yeu_Em\",\n",
    "    2: \"An_Tet_Ben_Con\",\n",
    "    3: \"Bay_Ngot_Ngao\",\n",
    "    4: \"Benh_Vien_Ma\",\n",
    "    5: \"Bi_Mat_Lai_Bi_Mat\",\n",
    "    6: \"Bi_Mat_Trong_Suong_Mu\",\n",
    "    7: \"Bo_Tu_Oan_Gia\",\n",
    "    8: \"Cho_Em_Den_Ngay_Mai\",\n",
    "    9: \"Chu_Tich_Giao_Hang\",\n",
    "    10: \"Chuyen_Tet\",\n",
    "    11: \"Co_Ba_Sai_Gon\",\n",
    "    12: \"Dao_Pho_Va_Piano\",\n",
    "    13: \"Dat_Phuong_Nam\",\n",
    "    14: \"Dia_Dao\",\n",
    "    15: \"Dinh_Menh_Thien_Y\",\n",
    "    16: \"Em_Chua_18\",\n",
    "    17: \"Em_La_Cua_Em\",\n",
    "    18: \"Gai_Gia_Lam_Chieu_3\",\n",
    "    19: \"Gia_Ngheo_Gap_Phat\",\n",
    "    20: \"Hem_Cut\",\n",
    "    21: \"Hoan_Doi\",\n",
    "    22: \"Ke_An_Danh\",\n",
    "    23: \"Ke_An_Hon\",\n",
    "    24: \"Lam_Giau_Voi_Ma\",\n",
    "    25: \"Lat_Mat_1\",\n",
    "    26: \"Lo_Mat\",\n",
    "    27: \"Ma_Da\",\n",
    "    28: \"Mat_Biec\",\n",
    "    29: \"Nhung_Nu_Hon_Ruc_Ro\",\n",
    "    30: \"Oan_Linh__Phan_1\",\n",
    "    31: \"Ong_Ngoai_Tuoi_30\",\n",
    "    32: \"Phap_Su_Tap_Su\",\n",
    "    33: \"Quy_Co_Thua_Ke\",\n",
    "    34: \"Ra_Mat_Gia_Tien\",\n",
    "    35: \"Sieu_Lua_Gap_Sieu_Lay\",\n",
    "    36: \"Sieu_Quay\",\n",
    "    37: \"Sieu_Tro_Ly\",\n",
    "    38: \"Taxi_Em_Ten_Gi\",\n",
    "    39: \"The_Call\",\n",
    "    40: \"Thien_Menh_Anh_Hung\",\n",
    "    41: \"Tieu_Thu_Va_Ba_Dau_Gau\",\n",
    "    42: \"Tren_Ban_Nhau_Duoi_Ban_Muu\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:08:05.702558Z",
     "iopub.status.busy": "2025-05-10T13:08:05.701636Z",
     "iopub.status.idle": "2025-05-10T13:08:18.464287Z",
     "shell.execute_reply": "2025-05-10T13:08:18.463752Z",
     "shell.execute_reply.started": "2025-05-10T13:08:05.702523Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39833 files belonging to 42 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = '/kaggle/input/frames-film-vietnam-dataset/Frame_Train'\n",
    "\n",
    "train_df = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_path,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',  \n",
    "    seed=1,\n",
    "    image_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:08:22.399474Z",
     "iopub.status.busy": "2025-05-10T13:08:22.398955Z",
     "iopub.status.idle": "2025-05-10T13:08:22.882416Z",
     "shell.execute_reply": "2025-05-10T13:08:22.881644Z",
     "shell.execute_reply.started": "2025-05-10T13:08:22.399444Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_df))  \n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(5, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for img, ax in zip(images[:9], axes): \n",
    "    ax.imshow(img.numpy().astype(\"uint8\"))  \n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X√≥a file trong th∆∞ m·ª•c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T14:11:36.459297Z",
     "iopub.status.busy": "2025-05-10T14:11:36.459019Z",
     "iopub.status.idle": "2025-05-10T14:11:36.482402Z",
     "shell.execute_reply": "2025-05-10T14:11:36.481890Z",
     "shell.execute_reply.started": "2025-05-10T14:11:36.459277Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def delete_all_in_folder(folder_path):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)  # x√≥a file ho·∫∑c symbolic link\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)  # x√≥a th∆∞ m·ª•c v√† to√†n b·ªô n·ªôi dung b√™n trong\n",
    "        except Exception as e:\n",
    "            print(f\"Kh√¥ng th·ªÉ x√≥a {file_path}: {e}\")\n",
    "\n",
    "# V√≠ d·ª•:\n",
    "folder = \"/kaggle/working/\"\n",
    "delete_all_in_folder(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:57:40.459483Z",
     "iopub.status.busy": "2025-05-10T13:57:40.458787Z",
     "iopub.status.idle": "2025-05-10T13:57:42.739010Z",
     "shell.execute_reply": "2025-05-10T13:57:42.738351Z",
     "shell.execute_reply.started": "2025-05-10T13:57:40.459459Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet50 + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T11:26:08.068758Z",
     "iopub.status.busy": "2025-05-10T11:26:08.068045Z",
     "iopub.status.idle": "2025-05-10T11:27:25.406277Z",
     "shell.execute_reply": "2025-05-10T11:27:25.405392Z",
     "shell.execute_reply.started": "2025-05-10T11:26:08.068733Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|          | 0/312 [00:00<?, ?it/s]I0000 00:00:1746876371.688650      31 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 312/312 [01:13<00:00,  4.22it/s]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# S·ªë batch\n",
    "num_batches = tf.data.experimental.cardinality(train_df).numpy()\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# Kh·ªüi t·∫°o model trong context c·ªßa strategy\n",
    "with strategy.scope():\n",
    "    base_model_resnet50 = ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg',\n",
    "        input_shape=(image_size, image_size, 3)\n",
    "    )\n",
    "\n",
    "# N∆°i l∆∞u ƒë·∫∑c tr∆∞ng v√† nh√£n\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "# L·∫∑p qua t·ª´ng batch\n",
    "for images, labels in tqdm(train_df, total=num_batches, desc=\"Extracting features\"):\n",
    "    images_pp = preprocess_input(images)\n",
    "    features_batch = base_model_resnet50(images_pp, training=False)\n",
    "    all_features.append(features_batch.numpy())\n",
    "    all_labels.append(labels.numpy())\n",
    "\n",
    "# ƒê√°nh nh√£n ·ª©ng v·ªõi ƒë·∫∑c tr∆∞ng\n",
    "features_array = np.concatenate(all_features, axis=0)\n",
    "labels_array = np.concatenate(all_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T11:28:09.125380Z",
     "iopub.status.busy": "2025-05-10T11:28:09.125099Z",
     "iopub.status.idle": "2025-05-10T11:30:22.425631Z",
     "shell.execute_reply": "2025-05-10T11:30:22.424913Z",
     "shell.execute_reply.started": "2025-05-10T11:28:09.125359Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M√¥ h√¨nh KNN ƒë√£ ƒë∆∞·ª£c l∆∞u d∆∞·ªõi d·∫°ng ONNX.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Hu·∫•n luy·ªán m√¥ h√¨nh KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(features_array, labels_array)\n",
    "\n",
    "# Chuy·ªÉn ƒë·ªïi m√¥ h√¨nh KNN sang ONNX\n",
    "onnx_model = convert_sklearn(\n",
    "    knn, \n",
    "    initial_types=[('input', FloatTensorType([None, features_array.shape[1]]))],\n",
    "    options={id(knn): {'zipmap': False}}  \n",
    ")\n",
    "\n",
    "# L∆∞u m√¥ h√¨nh d∆∞·ªõi d·∫°ng ONNX\n",
    "with open(\"knn_model.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print(\"M√¥ h√¨nh KNN ƒë√£ ƒë∆∞·ª£c l∆∞u d∆∞·ªõi d·∫°ng ONNX.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-10T11:30:45.092946Z",
     "iopub.status.busy": "2025-05-10T11:30:45.092656Z",
     "iopub.status.idle": "2025-05-10T11:41:43.152741Z",
     "shell.execute_reply": "2025-05-10T11:41:43.152004Z",
     "shell.execute_reply.started": "2025-05-10T11:30:45.092927Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# C√†i ƒë·∫∑t c√°c tham s·ªë\n",
    "image_size = 128\n",
    "test_path = \"/kaggle/input/frames-film-vietnam-dataset/Frame_Test\"\n",
    "onnx_model_path = \"/kaggle/working/knn_model.onnx\"\n",
    "confusion_output_path = \"confusion_matrix_knn.jpg\"\n",
    "csv_output_path = \"classification_report_knn.csv\"\n",
    "n_per_class = 50 \n",
    "\n",
    "# ==== Load m√¥ h√¨nh v√† ONNX ====\n",
    "model = ResNet50(include_top=False, weights='imagenet', pooling='avg', input_shape=(image_size, image_size, 3))\n",
    "\n",
    "# Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n m√¥ h√¨nh ONNX\n",
    "if not os.path.exists(onnx_model_path):\n",
    "    print(f\"‚ùå Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh ONNX t·∫°i: {onnx_model_path}\")\n",
    "\n",
    "# Kh·ªüi t·∫°o session ONNX v·ªõi providers r√µ r√†ng\n",
    "try:\n",
    "    # Ki·ªÉm tra GPU, n·∫øu c√≥ s·∫Ω s·ª≠ d·ª•ng CUDA\n",
    "    providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if 'CUDAExecutionProvider' in ort.get_available_providers() else ['CPUExecutionProvider']\n",
    "    onnx_session = ort.InferenceSession(onnx_model_path, providers=providers)\n",
    "    \n",
    "    # In th√¥ng tin ƒë·∫ßu v√†o ƒë·ªÉ ki·ªÉm tra\n",
    "    input_details = onnx_session.get_inputs()[0]\n",
    "    print(f\"‚úÖ M√¥ h√¨nh ONNX ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!\")\n",
    "    # print(f\"   - T√™n ƒë·∫ßu v√†o: {input_details.name}\")\n",
    "    # print(f\"   - H√¨nh d·∫°ng ƒë·∫ßu v√†o: {input_details.shape}\")\n",
    "    # print(f\"   - Ki·ªÉu d·ªØ li·ªáu ƒë·∫ßu v√†o: {input_details.type}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh ONNX: {e}\")\n",
    "\n",
    "# ==== Mapping classes ====\n",
    "classes = {\n",
    "    1: \"21_Ngay_Yeu_Em\", 2: \"An_Tet_Ben_Con\", 3: \"Bay_Ngot_Ngao\", 4: \"Benh_Vien_Ma\",\n",
    "    5: \"Bi_Mat_Lai_Bi_Mat\", 6: \"Bi_Mat_Trong_Suong_Mu\", 7: \"Bo_Tu_Oan_Gia\", 8: \"Cho_Em_Den_Ngay_Mai\",\n",
    "    9: \"Chu_Tich_Giao_Hang\", 10: \"Chuyen_Tet\", 11: \"Co_Ba_Sai_Gon\", 12: \"Dao_Pho_Va_Piano\",\n",
    "    13: \"Dat_Phuong_Nam\", 14: \"Dia_Dao\", 15: \"Dinh_Menh_Thien_Y\", 16: \"Em_Chua_18\",\n",
    "    17: \"Em_La_Cua_Em\", 18: \"Gai_Gia_Lam_Chieu_3\", 19: \"Gia_Ngheo_Gap_Phat\", 20: \"Hem_Cut\",\n",
    "    21: \"Hoan_Doi\", 22: \"Ke_An_Danh\", 23: \"Ke_An_Hon\", 24: \"Lam_Giau_Voi_Ma\",\n",
    "    25: \"Lat_Mat_1\", 26: \"Lo_Mat\", 27: \"Ma_Da\", 28: \"Mat_Biec\",\n",
    "    29: \"Nhung_Nu_Hon_Ruc_Ro\", 30: \"Oan_Linh__Phan_1\", 31: \"Ong_Ngoai_Tuoi_30\",\n",
    "    32: \"Phap_Su_Tap_Su\", 33: \"Quy_Co_Thua_Ke\", 34: \"Ra_Mat_Gia_Tien\",\n",
    "    35: \"Sieu_Lua_Gap_Sieu_Lay\", 36: \"Sieu_Quay\", 37: \"Sieu_Tro_Ly\",\n",
    "    38: \"Taxi_Em_Ten_Gi\", 39: \"The_Call\", 40: \"Thien_Menh_Anh_Hung\",\n",
    "    41: \"Tieu_Thu_Va_Ba_Dau_Gau\", 42: \"Tren_Ban_Nhau_Duoi_Ban_Muu\"\n",
    "}\n",
    "class_to_idx = {name: idx for idx, name in classes.items()}\n",
    "idx_to_class = {idx: name for name, idx in class_to_idx.items()}\n",
    "\n",
    "# ==== Duy·ªát t·∫≠p test v√† l·∫•y ·∫£nh t·ª´ m·ªói th∆∞ m·ª•c ====\n",
    "y_true = []\n",
    "y_pred = []\n",
    "all_images = []\n",
    "\n",
    "for class_name in os.listdir(test_path):\n",
    "    class_dir = os.path.join(test_path, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "\n",
    "    # L·∫•y danh s√°ch ·∫£nh trong th∆∞ m·ª•c n√†y\n",
    "    image_files = [\n",
    "        os.path.join(class_dir, f)\n",
    "        for f in os.listdir(class_dir)\n",
    "        if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "    ]\n",
    "\n",
    "    # L·∫•y ng·∫´u nhi√™n n ·∫£nh t·ª´ folder (ho·∫∑c √≠t h∆°n n·∫øu kh√¥ng ƒë·ªß)\n",
    "    selected_images = random.sample(image_files, min(n_per_class, len(image_files)))\n",
    "    all_images.extend(selected_images)\n",
    "\n",
    "# ==== D·ª± ƒëo√°n ====\n",
    "for img_path in tqdm(all_images, desc=\"Testing with KNN\"):\n",
    "    try:\n",
    "        folder_name = os.path.basename(os.path.dirname(img_path))\n",
    "        if folder_name not in class_to_idx:\n",
    "            print(f\"‚ùå Folder kh√¥ng h·ª£p l·ªá: {folder_name}\")\n",
    "            continue\n",
    "\n",
    "        img = image.load_img(img_path, target_size=(image_size, image_size))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        # Tr√≠ch ƒë·∫∑c tr∆∞ng v·ªõi ResNet50\n",
    "        feature = model.predict(x, verbose=0)\n",
    "        \n",
    "        if feature.ndim > 2:\n",
    "            feature = feature.reshape(1, -1)\n",
    "        \n",
    "        # V√¨ ch√∫ng ta ƒë·∫£m b·∫£o ƒë·∫ßu v√†o l√† float32 ƒë·ªÉ tr√°nh l·ªói ki·ªÉu d·ªØ li·ªáu\n",
    "        feature = feature.astype(np.float32)\n",
    "\n",
    "        # L·∫•y t√™n ƒë·∫ßu v√†o t·ª´ m√¥ h√¨nh ONNX ƒë·ªÉ ƒë·∫£m b·∫£o ƒë√∫ng\n",
    "        input_name = onnx_session.get_inputs()[0].name\n",
    "        \n",
    "        # D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh ONNX\n",
    "        outputs = onnx_session.run(None, {input_name: feature})\n",
    "        \n",
    "        if outputs[0].ndim == 2:  \n",
    "            pred_label = np.argmax(outputs[0][0]) + 1 \n",
    "        else:\n",
    "            pred_label = outputs[0][0]\n",
    "\n",
    "        y_true.append(class_to_idx[folder_name])\n",
    "        y_pred.append(pred_label)\n",
    "    except Exception as e:\n",
    "        print(f\"L·ªói ·∫£nh {img_path}: {e}\")\n",
    "        print(f\"  H√¨nh d·∫°ng ƒë·∫∑c tr∆∞ng: {feature.shape}, Ki·ªÉu d·ªØ li·ªáu: {feature.dtype}\")\n",
    "\n",
    "# print(f\"H√¨nh d·∫°ng ƒë·∫ßu ra: {[output.shape for output in outputs]}\")\n",
    "# print(f\"Ki·ªÉu ƒë·∫ßu ra: {[output.dtype for output in outputs]}\")\n",
    "# print(f\"Gi√° tr·ªã ƒë·∫ßu ra ƒë·∫ßu ti√™n: {outputs[0][0]}\")\n",
    "\n",
    "# ==== ƒê√°nh gi√° ====\n",
    "if len(y_true) == 0:\n",
    "    print(\"‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ƒë√°nh gi√°!\")\n",
    "else:\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    if y_pred.ndim > 1 and y_pred.shape[1] > 1:\n",
    "        y_pred = np.argmax(y_pred, axis=1) + 1\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "\n",
    "    print(f\"\\n‚úÖ Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"‚úÖ ƒê√∫ng: {np.sum(y_true == y_pred)} / ‚ùå Sai: {np.sum(y_true != y_pred)}\")\n",
    "\n",
    "    # ==== Confusion Matrix ====\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    class_labels = [classes[i] for i in sorted(classes.keys())]\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "    fig, ax = plt.subplots(figsize=(16, 16))\n",
    "    disp.plot(xticks_rotation=90, cmap='Blues', ax=ax, colorbar=False)\n",
    "    plt.title(\"Confusion Matrix (KNN)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(confusion_output_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"\\nüñºÔ∏è Confusion matrix ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o '{confusion_output_path}'\")\n",
    "\n",
    "    # ==== Classification Report ====\n",
    "    print(\"\\nüìÑ Classification Report:\")\n",
    "    report = classification_report(\n",
    "        y_true, y_pred, target_names=class_labels,\n",
    "        digits=2, output_dict=True\n",
    "    )\n",
    "\n",
    "    # Chuy·ªÉn b√°o c√°o ph√¢n lo·∫°i th√†nh DataFrame\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    if \"accuracy\" not in report_df.columns:\n",
    "        report_df[\"accuracy\"] = accuracy\n",
    "    print(report_df[[\"precision\", \"recall\", \"f1-score\", \"accuracy\"]])\n",
    "\n",
    "    # Hi·ªÉn th·ªã c√°c tham s·ªë chung cho to√†n b·ªô ch∆∞∆°ng tr√¨nh\n",
    "    avg_precision = np.mean(report_df['precision'])\n",
    "    avg_recall = np.mean(report_df['recall'])\n",
    "    avg_f1 = np.mean(report_df['f1-score'])\n",
    "\n",
    "    print(\"\\nüìù C√°c tham s·ªë ƒë√°nh gi√° chung:\")\n",
    "    print(f\"  - Precision: {avg_precision:.2f}\")\n",
    "    print(f\"  - Recall: {avg_recall:.2f}\")\n",
    "    print(f\"  - F1-score: {avg_f1:.2f}\")\n",
    "    print(f\"  - Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # L∆∞u b√°o c√°o chi ti·∫øt v√†o t·ªáp CSV\n",
    "    report_df.to_csv(csv_output_path, index=True)\n",
    "    print(f\"\\nüìä B√°o c√°o ph√¢n lo·∫°i ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o '{csv_output_path}'\")\n",
    "\n",
    "    # L∆∞u c√°c tham s·ªë ƒë√°nh gi√° chung v√†o t·ªáp CSV\n",
    "    evaluation_metrics = {\n",
    "        'precision': avg_precision,\n",
    "        'recall': avg_recall,\n",
    "        'f1-score': avg_f1,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "    evaluation_df = pd.DataFrame([evaluation_metrics])\n",
    "    evaluation_df.to_csv('evaluation_metrics_knn.csv', index=False)\n",
    "    print(f\"\\nüìä C√°c tham s·ªë ƒë√°nh gi√° chung ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'evaluation_metrics_knn.csv'\")\n",
    "\n",
    "    # L∆∞u c·∫£ b√°o c√°o ph√¢n lo·∫°i v√† c√°c tham s·ªë chung v√†o m·ªôt t·ªáp CSV\n",
    "    final_df = report_df.copy()\n",
    "    final_df['average_precision'] = avg_precision\n",
    "    final_df['average_recall'] = avg_recall\n",
    "    final_df['average_f1-score'] = avg_f1\n",
    "    final_df['average_accuracy'] = accuracy\n",
    "    final_df.to_csv('final_classification_report_knn.csv', index=True)\n",
    "    print(f\"\\nüìä B√°o c√°o ph√¢n lo·∫°i cu·ªëi c√πng ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'final_classification_report_knn.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNetB4 + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:23:07.841289Z",
     "iopub.status.busy": "2025-05-10T13:23:07.841015Z",
     "iopub.status.idle": "2025-05-10T13:25:44.486068Z",
     "shell.execute_reply": "2025-05-10T13:25:44.485306Z",
     "shell.execute_reply.started": "2025-05-10T13:23:07.841271Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n",
      "\u001b[1m71686520/71686520\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features with EfficientNetB4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 312/312 [02:33<00:00,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "# S·ªë batch\n",
    "num_batches = tf.data.experimental.cardinality(train_df).numpy()\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# Kh·ªüi t·∫°o EfficientNetB4 trong context c·ªßa strategy\n",
    "with strategy.scope():\n",
    "    base_model_efficientnetb4 = EfficientNetB4(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg',\n",
    "        input_shape=(image_size, image_size, 3)\n",
    "    )\n",
    "\n",
    "# N∆°i l∆∞u ƒë·∫∑c tr∆∞ng v√† nh√£n\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "# L·∫∑p qua t·ª´ng batch\n",
    "for images, labels in tqdm(train_df, total=num_batches, desc=\"Extracting features with EfficientNetB4\"):\n",
    "    images_pp = preprocess_input(images)\n",
    "    features_batch = base_model_efficientnetb4(images_pp, training=False)\n",
    "    all_features.append(features_batch.numpy())\n",
    "    all_labels.append(labels.numpy())\n",
    "\n",
    "# K·∫øt h·ª£p ƒë·∫∑c tr∆∞ng v√† nh√£n\n",
    "features_array = np.concatenate(all_features, axis=0)\n",
    "labels_array = np.concatenate(all_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:25:52.239273Z",
     "iopub.status.busy": "2025-05-10T13:25:52.238560Z",
     "iopub.status.idle": "2025-05-10T13:27:48.336727Z",
     "shell.execute_reply": "2025-05-10T13:27:48.336022Z",
     "shell.execute_reply.started": "2025-05-10T13:25:52.239249Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M√¥ h√¨nh KNN ƒë√£ ƒë∆∞·ª£c l∆∞u d∆∞·ªõi d·∫°ng ONNX.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Hu·∫•n luy·ªán m√¥ h√¨nh KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(features_array, labels_array)\n",
    "\n",
    "# Chuy·ªÉn ƒë·ªïi m√¥ h√¨nh KNN sang ONNX\n",
    "onnx_model = convert_sklearn(\n",
    "    knn, \n",
    "    initial_types=[('input', FloatTensorType([None, features_array.shape[1]]))],\n",
    "    options={id(knn): {'zipmap': False}}  \n",
    ")\n",
    "\n",
    "# L∆∞u m√¥ h√¨nh d∆∞·ªõi d·∫°ng ONNX\n",
    "with open(\"knn_model.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print(\"M√¥ h√¨nh KNN ƒë√£ ƒë∆∞·ª£c l∆∞u d∆∞·ªõi d·∫°ng ONNX.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:28:03.169943Z",
     "iopub.status.busy": "2025-05-10T13:28:03.169581Z",
     "iopub.status.idle": "2025-05-10T13:38:33.767574Z",
     "shell.execute_reply": "2025-05-10T13:38:33.766806Z",
     "shell.execute_reply.started": "2025-05-10T13:28:03.169921Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# C√†i ƒë·∫∑t c√°c tham s·ªë\n",
    "image_size = 128\n",
    "test_path = \"/kaggle/input/frames-film-vietnam-dataset/Frame_Test\"\n",
    "onnx_model_path = \"/kaggle/working/knn_model.onnx\"\n",
    "confusion_output_path = \"confusion_matrix_knn.jpg\"\n",
    "csv_output_path = \"classification_report_knn.csv\"\n",
    "n_per_class = 50 \n",
    "\n",
    "# ==== Load m√¥ h√¨nh v√† ONNX ====\n",
    "model = EfficientNetB4(include_top=False, weights='imagenet', pooling='avg', input_shape=(image_size, image_size, 3))\n",
    "\n",
    "# Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n m√¥ h√¨nh ONNX\n",
    "if not os.path.exists(onnx_model_path):\n",
    "    print(f\"‚ùå Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh ONNX t·∫°i: {onnx_model_path}\")\n",
    "\n",
    "# Kh·ªüi t·∫°o session ONNX v·ªõi providers r√µ r√†ng\n",
    "try:\n",
    "    # Ki·ªÉm tra GPU, n·∫øu c√≥ s·∫Ω s·ª≠ d·ª•ng CUDA\n",
    "    providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if 'CUDAExecutionProvider' in ort.get_available_providers() else ['CPUExecutionProvider']\n",
    "    onnx_session = ort.InferenceSession(onnx_model_path, providers=providers)\n",
    "    \n",
    "    # In th√¥ng tin ƒë·∫ßu v√†o ƒë·ªÉ ki·ªÉm tra\n",
    "    input_details = onnx_session.get_inputs()[0]\n",
    "    print(f\"‚úÖ M√¥ h√¨nh ONNX ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!\")\n",
    "    # print(f\"   - T√™n ƒë·∫ßu v√†o: {input_details.name}\")\n",
    "    # print(f\"   - H√¨nh d·∫°ng ƒë·∫ßu v√†o: {input_details.shape}\")\n",
    "    # print(f\"   - Ki·ªÉu d·ªØ li·ªáu ƒë·∫ßu v√†o: {input_details.type}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh ONNX: {e}\")\n",
    "\n",
    "# ==== Mapping classes ====\n",
    "classes = {\n",
    "    1: \"21_Ngay_Yeu_Em\", 2: \"An_Tet_Ben_Con\", 3: \"Bay_Ngot_Ngao\", 4: \"Benh_Vien_Ma\",\n",
    "    5: \"Bi_Mat_Lai_Bi_Mat\", 6: \"Bi_Mat_Trong_Suong_Mu\", 7: \"Bo_Tu_Oan_Gia\", 8: \"Cho_Em_Den_Ngay_Mai\",\n",
    "    9: \"Chu_Tich_Giao_Hang\", 10: \"Chuyen_Tet\", 11: \"Co_Ba_Sai_Gon\", 12: \"Dao_Pho_Va_Piano\",\n",
    "    13: \"Dat_Phuong_Nam\", 14: \"Dia_Dao\", 15: \"Dinh_Menh_Thien_Y\", 16: \"Em_Chua_18\",\n",
    "    17: \"Em_La_Cua_Em\", 18: \"Gai_Gia_Lam_Chieu_3\", 19: \"Gia_Ngheo_Gap_Phat\", 20: \"Hem_Cut\",\n",
    "    21: \"Hoan_Doi\", 22: \"Ke_An_Danh\", 23: \"Ke_An_Hon\", 24: \"Lam_Giau_Voi_Ma\",\n",
    "    25: \"Lat_Mat_1\", 26: \"Lo_Mat\", 27: \"Ma_Da\", 28: \"Mat_Biec\",\n",
    "    29: \"Nhung_Nu_Hon_Ruc_Ro\", 30: \"Oan_Linh__Phan_1\", 31: \"Ong_Ngoai_Tuoi_30\",\n",
    "    32: \"Phap_Su_Tap_Su\", 33: \"Quy_Co_Thua_Ke\", 34: \"Ra_Mat_Gia_Tien\",\n",
    "    35: \"Sieu_Lua_Gap_Sieu_Lay\", 36: \"Sieu_Quay\", 37: \"Sieu_Tro_Ly\",\n",
    "    38: \"Taxi_Em_Ten_Gi\", 39: \"The_Call\", 40: \"Thien_Menh_Anh_Hung\",\n",
    "    41: \"Tieu_Thu_Va_Ba_Dau_Gau\", 42: \"Tren_Ban_Nhau_Duoi_Ban_Muu\"\n",
    "}\n",
    "class_to_idx = {name: idx for idx, name in classes.items()}\n",
    "idx_to_class = {idx: name for name, idx in class_to_idx.items()}\n",
    "\n",
    "# ==== Duy·ªát t·∫≠p test v√† l·∫•y ·∫£nh t·ª´ m·ªói th∆∞ m·ª•c ====\n",
    "y_true = []\n",
    "y_pred = []\n",
    "all_images = []\n",
    "\n",
    "for class_name in os.listdir(test_path):\n",
    "    class_dir = os.path.join(test_path, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "\n",
    "    # L·∫•y danh s√°ch ·∫£nh trong th∆∞ m·ª•c n√†y\n",
    "    image_files = [\n",
    "        os.path.join(class_dir, f)\n",
    "        for f in os.listdir(class_dir)\n",
    "        if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "    ]\n",
    "\n",
    "    # L·∫•y ng·∫´u nhi√™n n ·∫£nh t·ª´ folder (ho·∫∑c √≠t h∆°n n·∫øu kh√¥ng ƒë·ªß)\n",
    "    selected_images = random.sample(image_files, min(n_per_class, len(image_files)))\n",
    "    all_images.extend(selected_images)\n",
    "\n",
    "# ==== D·ª± ƒëo√°n ====\n",
    "for img_path in tqdm(all_images, desc=\"Testing with KNN\"):\n",
    "    try:\n",
    "        folder_name = os.path.basename(os.path.dirname(img_path))\n",
    "        if folder_name not in class_to_idx:\n",
    "            print(f\"‚ùå Folder kh√¥ng h·ª£p l·ªá: {folder_name}\")\n",
    "            continue\n",
    "\n",
    "        img = image.load_img(img_path, target_size=(image_size, image_size))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        # Tr√≠ch ƒë·∫∑c tr∆∞ng v·ªõi ResNet50\n",
    "        feature = model.predict(x, verbose=0)\n",
    "        \n",
    "        if feature.ndim > 2:\n",
    "            feature = feature.reshape(1, -1)\n",
    "        \n",
    "        # V√¨ ch√∫ng ta ƒë·∫£m b·∫£o ƒë·∫ßu v√†o l√† float32 ƒë·ªÉ tr√°nh l·ªói ki·ªÉu d·ªØ li·ªáu\n",
    "        feature = feature.astype(np.float32)\n",
    "\n",
    "        # L·∫•y t√™n ƒë·∫ßu v√†o t·ª´ m√¥ h√¨nh ONNX ƒë·ªÉ ƒë·∫£m b·∫£o ƒë√∫ng\n",
    "        input_name = onnx_session.get_inputs()[0].name\n",
    "        \n",
    "        # D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh ONNX\n",
    "        outputs = onnx_session.run(None, {input_name: feature})\n",
    "        \n",
    "        if outputs[0].ndim == 2:  \n",
    "            pred_label = np.argmax(outputs[0][0]) + 1 \n",
    "        else:\n",
    "            pred_label = outputs[0][0]\n",
    "\n",
    "        y_true.append(class_to_idx[folder_name])\n",
    "        y_pred.append(pred_label)\n",
    "    except Exception as e:\n",
    "        print(f\"L·ªói ·∫£nh {img_path}: {e}\")\n",
    "        print(f\"  H√¨nh d·∫°ng ƒë·∫∑c tr∆∞ng: {feature.shape}, Ki·ªÉu d·ªØ li·ªáu: {feature.dtype}\")\n",
    "\n",
    "# print(f\"H√¨nh d·∫°ng ƒë·∫ßu ra: {[output.shape for output in outputs]}\")\n",
    "# print(f\"Ki·ªÉu ƒë·∫ßu ra: {[output.dtype for output in outputs]}\")\n",
    "# print(f\"Gi√° tr·ªã ƒë·∫ßu ra ƒë·∫ßu ti√™n: {outputs[0][0]}\")\n",
    "\n",
    "# ==== ƒê√°nh gi√° ====\n",
    "if len(y_true) == 0:\n",
    "    print(\"‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ƒë√°nh gi√°!\")\n",
    "else:\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    if y_pred.ndim > 1 and y_pred.shape[1] > 1:\n",
    "        y_pred = np.argmax(y_pred, axis=1) + 1\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "\n",
    "    print(f\"\\n‚úÖ Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"‚úÖ ƒê√∫ng: {np.sum(y_true == y_pred)} / ‚ùå Sai: {np.sum(y_true != y_pred)}\")\n",
    "\n",
    "    # ==== Confusion Matrix ====\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    class_labels = [classes[i] for i in sorted(classes.keys())]\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "    fig, ax = plt.subplots(figsize=(16, 16))\n",
    "    disp.plot(xticks_rotation=90, cmap='Blues', ax=ax, colorbar=False)\n",
    "    plt.title(\"Confusion Matrix (KNN)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(confusion_output_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"\\nüñºÔ∏è Confusion matrix ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o '{confusion_output_path}'\")\n",
    "\n",
    "    # ==== Classification Report ====\n",
    "    print(\"\\nüìÑ Classification Report:\")\n",
    "    report = classification_report(\n",
    "        y_true, y_pred, target_names=class_labels,\n",
    "        digits=2, output_dict=True\n",
    "    )\n",
    "\n",
    "    # Chuy·ªÉn b√°o c√°o ph√¢n lo·∫°i th√†nh DataFrame\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    if \"accuracy\" not in report_df.columns:\n",
    "        report_df[\"accuracy\"] = accuracy\n",
    "    print(report_df[[\"precision\", \"recall\", \"f1-score\", \"accuracy\"]])\n",
    "\n",
    "    # Hi·ªÉn th·ªã c√°c tham s·ªë chung cho to√†n b·ªô ch∆∞∆°ng tr√¨nh\n",
    "    avg_precision = np.mean(report_df['precision'])\n",
    "    avg_recall = np.mean(report_df['recall'])\n",
    "    avg_f1 = np.mean(report_df['f1-score'])\n",
    "\n",
    "    print(\"\\nüìù C√°c tham s·ªë ƒë√°nh gi√° chung:\")\n",
    "    print(f\"  - Precision: {avg_precision:.2f}\")\n",
    "    print(f\"  - Recall: {avg_recall:.2f}\")\n",
    "    print(f\"  - F1-score: {avg_f1:.2f}\")\n",
    "    print(f\"  - Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # L∆∞u b√°o c√°o chi ti·∫øt v√†o t·ªáp CSV\n",
    "    report_df.to_csv(csv_output_path, index=True)\n",
    "    print(f\"\\nüìä B√°o c√°o ph√¢n lo·∫°i ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o '{csv_output_path}'\")\n",
    "\n",
    "    # L∆∞u c√°c tham s·ªë ƒë√°nh gi√° chung v√†o t·ªáp CSV\n",
    "    evaluation_metrics = {\n",
    "        'precision': avg_precision,\n",
    "        'recall': avg_recall,\n",
    "        'f1-score': avg_f1,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "    evaluation_df = pd.DataFrame([evaluation_metrics])\n",
    "    evaluation_df.to_csv('evaluation_metrics_knn.csv', index=False)\n",
    "    print(f\"\\nüìä C√°c tham s·ªë ƒë√°nh gi√° chung ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'evaluation_metrics_knn.csv'\")\n",
    "\n",
    "    # L∆∞u c·∫£ b√°o c√°o ph√¢n lo·∫°i v√† c√°c tham s·ªë chung v√†o m·ªôt t·ªáp CSV\n",
    "    final_df = report_df.copy()\n",
    "    final_df['average_precision'] = avg_precision\n",
    "    final_df['average_recall'] = avg_recall\n",
    "    final_df['average_f1-score'] = avg_f1\n",
    "    final_df['average_accuracy'] = accuracy\n",
    "    final_df.to_csv('final_classification_report_knn.csv', index=True)\n",
    "    print(f\"\\nüìä B√°o c√°o ph√¢n lo·∫°i cu·ªëi c√πng ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'final_classification_report_knn.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionV3 + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:16:41.954772Z",
     "iopub.status.busy": "2025-05-10T12:16:41.954070Z",
     "iopub.status.idle": "2025-05-10T12:18:14.516721Z",
     "shell.execute_reply": "2025-05-10T12:18:14.515910Z",
     "shell.execute_reply.started": "2025-05-10T12:16:41.954742Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m87910968/87910968\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features with InceptionV3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 312/312 [01:30<00:00,  3.46it/s]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "# Gi·∫£ s·ª≠ bi·∫øn train_df l√† tf.data.Dataset ƒë√£ chu·∫©n h√≥a v√† batch ƒë√∫ng\n",
    "num_batches = tf.data.experimental.cardinality(train_df).numpy()\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# Kh·ªüi t·∫°o InceptionV3 trong context c·ªßa strategy\n",
    "with strategy.scope():\n",
    "    base_model_inceptionv3 = InceptionV3(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg',\n",
    "        input_shape=(image_size, image_size, 3)\n",
    "    )\n",
    "\n",
    "# Tr√≠ch ƒë·∫∑c tr∆∞ng v√† nh√£n\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "for images, labels in tqdm(train_df, total=num_batches, desc=\"Extracting features with InceptionV3\"):\n",
    "    images_pp = preprocess_input(images)\n",
    "    features_batch = base_model_inceptionv3(images_pp, training=False)\n",
    "    all_features.append(features_batch.numpy())\n",
    "    all_labels.append(labels.numpy())\n",
    "\n",
    "features_array = np.concatenate(all_features, axis=0)   \n",
    "labels_array = np.concatenate(all_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:18:46.224602Z",
     "iopub.status.busy": "2025-05-10T12:18:46.223834Z",
     "iopub.status.idle": "2025-05-10T12:21:01.942639Z",
     "shell.execute_reply": "2025-05-10T12:21:01.941882Z",
     "shell.execute_reply.started": "2025-05-10T12:18:46.224578Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M√¥ h√¨nh KNN ƒë√£ ƒë∆∞·ª£c l∆∞u d∆∞·ªõi d·∫°ng ONNX.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Hu·∫•n luy·ªán m√¥ h√¨nh KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(features_array, labels_array)\n",
    "\n",
    "# Chuy·ªÉn ƒë·ªïi m√¥ h√¨nh KNN sang ONNX\n",
    "onnx_model = convert_sklearn(\n",
    "    knn, \n",
    "    initial_types=[('input', FloatTensorType([None, features_array.shape[1]]))],\n",
    "    options={id(knn): {'zipmap': False}}  \n",
    ")\n",
    "\n",
    "# L∆∞u m√¥ h√¨nh d∆∞·ªõi d·∫°ng ONNX\n",
    "with open(\"knn_model.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print(\"M√¥ h√¨nh KNN ƒë√£ ƒë∆∞·ª£c l∆∞u d∆∞·ªõi d·∫°ng ONNX.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-10T12:21:10.470500Z",
     "iopub.status.busy": "2025-05-10T12:21:10.469776Z",
     "iopub.status.idle": "2025-05-10T12:32:35.053032Z",
     "shell.execute_reply": "2025-05-10T12:32:35.052273Z",
     "shell.execute_reply.started": "2025-05-10T12:21:10.470459Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# C√†i ƒë·∫∑t c√°c tham s·ªë\n",
    "image_size = 128\n",
    "test_path = \"/kaggle/input/frames-film-vietnam-dataset/Frame_Test\"\n",
    "onnx_model_path = \"/kaggle/working/knn_model.onnx\"\n",
    "confusion_output_path = \"confusion_matrix_knn.jpg\"\n",
    "csv_output_path = \"classification_report_knn.csv\"\n",
    "n_per_class = 50 \n",
    "\n",
    "# ==== Load m√¥ h√¨nh v√† ONNX ====\n",
    "model = InceptionV3(include_top=False, weights='imagenet', pooling='avg', input_shape=(image_size, image_size, 3))\n",
    "\n",
    "# Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n m√¥ h√¨nh ONNX\n",
    "if not os.path.exists(onnx_model_path):\n",
    "    print(f\"‚ùå Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh ONNX t·∫°i: {onnx_model_path}\")\n",
    "\n",
    "# Kh·ªüi t·∫°o session ONNX v·ªõi providers r√µ r√†ng\n",
    "try:\n",
    "    # Ki·ªÉm tra GPU, n·∫øu c√≥ s·∫Ω s·ª≠ d·ª•ng CUDA\n",
    "    providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if 'CUDAExecutionProvider' in ort.get_available_providers() else ['CPUExecutionProvider']\n",
    "    onnx_session = ort.InferenceSession(onnx_model_path, providers=providers)\n",
    "    \n",
    "    # In th√¥ng tin ƒë·∫ßu v√†o ƒë·ªÉ ki·ªÉm tra\n",
    "    input_details = onnx_session.get_inputs()[0]\n",
    "    print(f\"‚úÖ M√¥ h√¨nh ONNX ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!\")\n",
    "    # print(f\"   - T√™n ƒë·∫ßu v√†o: {input_details.name}\")\n",
    "    # print(f\"   - H√¨nh d·∫°ng ƒë·∫ßu v√†o: {input_details.shape}\")\n",
    "    # print(f\"   - Ki·ªÉu d·ªØ li·ªáu ƒë·∫ßu v√†o: {input_details.type}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh ONNX: {e}\")\n",
    "\n",
    "# ==== Mapping classes ====\n",
    "classes = {\n",
    "    1: \"21_Ngay_Yeu_Em\", 2: \"An_Tet_Ben_Con\", 3: \"Bay_Ngot_Ngao\", 4: \"Benh_Vien_Ma\",\n",
    "    5: \"Bi_Mat_Lai_Bi_Mat\", 6: \"Bi_Mat_Trong_Suong_Mu\", 7: \"Bo_Tu_Oan_Gia\", 8: \"Cho_Em_Den_Ngay_Mai\",\n",
    "    9: \"Chu_Tich_Giao_Hang\", 10: \"Chuyen_Tet\", 11: \"Co_Ba_Sai_Gon\", 12: \"Dao_Pho_Va_Piano\",\n",
    "    13: \"Dat_Phuong_Nam\", 14: \"Dia_Dao\", 15: \"Dinh_Menh_Thien_Y\", 16: \"Em_Chua_18\",\n",
    "    17: \"Em_La_Cua_Em\", 18: \"Gai_Gia_Lam_Chieu_3\", 19: \"Gia_Ngheo_Gap_Phat\", 20: \"Hem_Cut\",\n",
    "    21: \"Hoan_Doi\", 22: \"Ke_An_Danh\", 23: \"Ke_An_Hon\", 24: \"Lam_Giau_Voi_Ma\",\n",
    "    25: \"Lat_Mat_1\", 26: \"Lo_Mat\", 27: \"Ma_Da\", 28: \"Mat_Biec\",\n",
    "    29: \"Nhung_Nu_Hon_Ruc_Ro\", 30: \"Oan_Linh__Phan_1\", 31: \"Ong_Ngoai_Tuoi_30\",\n",
    "    32: \"Phap_Su_Tap_Su\", 33: \"Quy_Co_Thua_Ke\", 34: \"Ra_Mat_Gia_Tien\",\n",
    "    35: \"Sieu_Lua_Gap_Sieu_Lay\", 36: \"Sieu_Quay\", 37: \"Sieu_Tro_Ly\",\n",
    "    38: \"Taxi_Em_Ten_Gi\", 39: \"The_Call\", 40: \"Thien_Menh_Anh_Hung\",\n",
    "    41: \"Tieu_Thu_Va_Ba_Dau_Gau\", 42: \"Tren_Ban_Nhau_Duoi_Ban_Muu\"\n",
    "}\n",
    "class_to_idx = {name: idx for idx, name in classes.items()}\n",
    "idx_to_class = {idx: name for name, idx in class_to_idx.items()}\n",
    "\n",
    "# ==== Duy·ªát t·∫≠p test v√† l·∫•y ·∫£nh t·ª´ m·ªói th∆∞ m·ª•c ====\n",
    "y_true = []\n",
    "y_pred = []\n",
    "all_images = []\n",
    "\n",
    "for class_name in os.listdir(test_path):\n",
    "    class_dir = os.path.join(test_path, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "\n",
    "    # L·∫•y danh s√°ch ·∫£nh trong th∆∞ m·ª•c n√†y\n",
    "    image_files = [\n",
    "        os.path.join(class_dir, f)\n",
    "        for f in os.listdir(class_dir)\n",
    "        if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "    ]\n",
    "\n",
    "    # L·∫•y ng·∫´u nhi√™n n ·∫£nh t·ª´ folder (ho·∫∑c √≠t h∆°n n·∫øu kh√¥ng ƒë·ªß)\n",
    "    selected_images = random.sample(image_files, min(n_per_class, len(image_files)))\n",
    "    all_images.extend(selected_images)\n",
    "\n",
    "# ==== D·ª± ƒëo√°n ====\n",
    "for img_path in tqdm(all_images, desc=\"Testing with KNN\"):\n",
    "    try:\n",
    "        folder_name = os.path.basename(os.path.dirname(img_path))\n",
    "        if folder_name not in class_to_idx:\n",
    "            print(f\"‚ùå Folder kh√¥ng h·ª£p l·ªá: {folder_name}\")\n",
    "            continue\n",
    "\n",
    "        img = image.load_img(img_path, target_size=(image_size, image_size))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        # Tr√≠ch ƒë·∫∑c tr∆∞ng v·ªõi ResNet50\n",
    "        feature = model.predict(x, verbose=0)\n",
    "        \n",
    "        if feature.ndim > 2:\n",
    "            feature = feature.reshape(1, -1)\n",
    "        \n",
    "        # V√¨ ch√∫ng ta ƒë·∫£m b·∫£o ƒë·∫ßu v√†o l√† float32 ƒë·ªÉ tr√°nh l·ªói ki·ªÉu d·ªØ li·ªáu\n",
    "        feature = feature.astype(np.float32)\n",
    "\n",
    "        # L·∫•y t√™n ƒë·∫ßu v√†o t·ª´ m√¥ h√¨nh ONNX ƒë·ªÉ ƒë·∫£m b·∫£o ƒë√∫ng\n",
    "        input_name = onnx_session.get_inputs()[0].name\n",
    "        \n",
    "        # D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh ONNX\n",
    "        outputs = onnx_session.run(None, {input_name: feature})\n",
    "        \n",
    "        if outputs[0].ndim == 2:  \n",
    "            pred_label = np.argmax(outputs[0][0]) + 1 \n",
    "        else:\n",
    "            pred_label = outputs[0][0]\n",
    "\n",
    "        y_true.append(class_to_idx[folder_name])\n",
    "        y_pred.append(pred_label)\n",
    "    except Exception as e:\n",
    "        print(f\"L·ªói ·∫£nh {img_path}: {e}\")\n",
    "        print(f\"  H√¨nh d·∫°ng ƒë·∫∑c tr∆∞ng: {feature.shape}, Ki·ªÉu d·ªØ li·ªáu: {feature.dtype}\")\n",
    "\n",
    "# print(f\"H√¨nh d·∫°ng ƒë·∫ßu ra: {[output.shape for output in outputs]}\")\n",
    "# print(f\"Ki·ªÉu ƒë·∫ßu ra: {[output.dtype for output in outputs]}\")\n",
    "# print(f\"Gi√° tr·ªã ƒë·∫ßu ra ƒë·∫ßu ti√™n: {outputs[0][0]}\")\n",
    "\n",
    "# ==== ƒê√°nh gi√° ====\n",
    "if len(y_true) == 0:\n",
    "    print(\"‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ƒë√°nh gi√°!\")\n",
    "else:\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    if y_pred.ndim > 1 and y_pred.shape[1] > 1:\n",
    "        y_pred = np.argmax(y_pred, axis=1) + 1\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "\n",
    "    print(f\"\\n‚úÖ Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"‚úÖ ƒê√∫ng: {np.sum(y_true == y_pred)} / ‚ùå Sai: {np.sum(y_true != y_pred)}\")\n",
    "\n",
    "    # ==== Confusion Matrix ====\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    class_labels = [classes[i] for i in sorted(classes.keys())]\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "    fig, ax = plt.subplots(figsize=(16, 16))\n",
    "    disp.plot(xticks_rotation=90, cmap='Blues', ax=ax, colorbar=False)\n",
    "    plt.title(\"Confusion Matrix (KNN)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(confusion_output_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"\\nüñºÔ∏è Confusion matrix ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o '{confusion_output_path}'\")\n",
    "\n",
    "    # ==== Classification Report ====\n",
    "    print(\"\\nüìÑ Classification Report:\")\n",
    "    report = classification_report(\n",
    "        y_true, y_pred, target_names=class_labels,\n",
    "        digits=2, output_dict=True\n",
    "    )\n",
    "\n",
    "    # Chuy·ªÉn b√°o c√°o ph√¢n lo·∫°i th√†nh DataFrame\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    if \"accuracy\" not in report_df.columns:\n",
    "        report_df[\"accuracy\"] = accuracy\n",
    "    print(report_df[[\"precision\", \"recall\", \"f1-score\", \"accuracy\"]])\n",
    "\n",
    "    # Hi·ªÉn th·ªã c√°c tham s·ªë chung cho to√†n b·ªô ch∆∞∆°ng tr√¨nh\n",
    "    avg_precision = np.mean(report_df['precision'])\n",
    "    avg_recall = np.mean(report_df['recall'])\n",
    "    avg_f1 = np.mean(report_df['f1-score'])\n",
    "\n",
    "    print(\"\\nüìù C√°c tham s·ªë ƒë√°nh gi√° chung:\")\n",
    "    print(f\"  - Precision: {avg_precision:.2f}\")\n",
    "    print(f\"  - Recall: {avg_recall:.2f}\")\n",
    "    print(f\"  - F1-score: {avg_f1:.2f}\")\n",
    "    print(f\"  - Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # L∆∞u b√°o c√°o chi ti·∫øt v√†o t·ªáp CSV\n",
    "    report_df.to_csv(csv_output_path, index=True)\n",
    "    print(f\"\\nüìä B√°o c√°o ph√¢n lo·∫°i ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o '{csv_output_path}'\")\n",
    "\n",
    "    # L∆∞u c√°c tham s·ªë ƒë√°nh gi√° chung v√†o t·ªáp CSV\n",
    "    evaluation_metrics = {\n",
    "        'precision': avg_precision,\n",
    "        'recall': avg_recall,\n",
    "        'f1-score': avg_f1,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "    evaluation_df = pd.DataFrame([evaluation_metrics])\n",
    "    evaluation_df.to_csv('evaluation_metrics_knn.csv', index=False)\n",
    "    print(f\"\\nüìä C√°c tham s·ªë ƒë√°nh gi√° chung ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'evaluation_metrics_knn.csv'\")\n",
    "\n",
    "    # L∆∞u c·∫£ b√°o c√°o ph√¢n lo·∫°i v√† c√°c tham s·ªë chung v√†o m·ªôt t·ªáp CSV\n",
    "    final_df = report_df.copy()\n",
    "    final_df['average_precision'] = avg_precision\n",
    "    final_df['average_recall'] = avg_recall\n",
    "    final_df['average_f1-score'] = avg_f1\n",
    "    final_df['average_accuracy'] = accuracy\n",
    "    final_df.to_csv('final_classification_report_knn.csv', index=True)\n",
    "    print(f\"\\nüìä B√°o c√°o ph√¢n lo·∫°i cu·ªëi c√πng ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'final_classification_report_knn.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 + KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T14:01:29.305738Z",
     "iopub.status.busy": "2025-05-10T14:01:29.305447Z",
     "iopub.status.idle": "2025-05-10T14:02:05.156482Z",
     "shell.execute_reply": "2025-05-10T14:02:05.155713Z",
     "shell.execute_reply.started": "2025-05-10T14:01:29.305715Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 312/312 [00:35<00:00,  8.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# S·ªë batch\n",
    "num_batches = tf.data.experimental.cardinality(train_df).numpy()\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    base_model_vgg16 = VGG16(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg',\n",
    "        input_shape=(image_size, image_size, 3)\n",
    "    )\n",
    "\n",
    "# N∆°i l∆∞u ƒë·∫∑c tr∆∞ng v√† nh√£n\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "for images, labels in tqdm(train_df, total=num_batches, desc=\"Extracting features\"):\n",
    "    images_pp = preprocess_input(images)\n",
    "    features_batch = base_model_vgg16(images_pp, training=False)\n",
    "    all_features.append(features_batch.numpy())\n",
    "    all_labels.append(labels.numpy())\n",
    "\n",
    "# N·ªëi ƒë·∫∑c tr∆∞ng v√† nh√£n\n",
    "features_array = np.concatenate(all_features, axis=0)\n",
    "labels_array = np.concatenate(all_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T14:02:10.190077Z",
     "iopub.status.busy": "2025-05-10T14:02:10.189795Z",
     "iopub.status.idle": "2025-05-10T14:02:46.379947Z",
     "shell.execute_reply": "2025-05-10T14:02:46.379176Z",
     "shell.execute_reply.started": "2025-05-10T14:02:10.190056Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M√¥ h√¨nh KNN ƒë√£ ƒë∆∞·ª£c l∆∞u d∆∞·ªõi d·∫°ng ONNX.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Hu·∫•n luy·ªán m√¥ h√¨nh KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(features_array, labels_array)\n",
    "\n",
    "# Chuy·ªÉn ƒë·ªïi m√¥ h√¨nh KNN sang ONNX\n",
    "onnx_model = convert_sklearn(\n",
    "    knn, \n",
    "    initial_types=[('input', FloatTensorType([None, features_array.shape[1]]))],\n",
    "    options={id(knn): {'zipmap': False}}  \n",
    ")\n",
    "\n",
    "# L∆∞u m√¥ h√¨nh d∆∞·ªõi d·∫°ng ONNX\n",
    "with open(\"knn_model.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print(\"M√¥ h√¨nh KNN ƒë√£ ƒë∆∞·ª£c l∆∞u d∆∞·ªõi d·∫°ng ONNX.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T14:02:54.311309Z",
     "iopub.status.busy": "2025-05-10T14:02:54.310995Z",
     "iopub.status.idle": "2025-05-10T14:09:44.090395Z",
     "shell.execute_reply": "2025-05-10T14:09:44.089811Z",
     "shell.execute_reply.started": "2025-05-10T14:02:54.311289Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# C√†i ƒë·∫∑t c√°c tham s·ªë\n",
    "image_size = 128\n",
    "test_path = \"/kaggle/input/frames-film-vietnam-dataset/Frame_Test\"\n",
    "onnx_model_path = \"/kaggle/working/knn_model.onnx\"\n",
    "confusion_output_path = \"confusion_matrix_knn.jpg\"\n",
    "csv_output_path = \"classification_report_knn.csv\"\n",
    "n_per_class = 50 \n",
    "\n",
    "# ==== Load m√¥ h√¨nh v√† ONNX ====\n",
    "model = VGG16(include_top=False, weights='imagenet', pooling='avg', input_shape=(image_size, image_size, 3))\n",
    "\n",
    "# Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n m√¥ h√¨nh ONNX\n",
    "if not os.path.exists(onnx_model_path):\n",
    "    print(f\"‚ùå Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh ONNX t·∫°i: {onnx_model_path}\")\n",
    "\n",
    "# Kh·ªüi t·∫°o session ONNX v·ªõi providers r√µ r√†ng\n",
    "try:\n",
    "    # Ki·ªÉm tra GPU, n·∫øu c√≥ s·∫Ω s·ª≠ d·ª•ng CUDA\n",
    "    providers = ['CUDAExecutionProvider', 'CPUExecutionProvider'] if 'CUDAExecutionProvider' in ort.get_available_providers() else ['CPUExecutionProvider']\n",
    "    onnx_session = ort.InferenceSession(onnx_model_path, providers=providers)\n",
    "    \n",
    "    # In th√¥ng tin ƒë·∫ßu v√†o ƒë·ªÉ ki·ªÉm tra\n",
    "    input_details = onnx_session.get_inputs()[0]\n",
    "    print(f\"‚úÖ M√¥ h√¨nh ONNX ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!\")\n",
    "    # print(f\"   - T√™n ƒë·∫ßu v√†o: {input_details.name}\")\n",
    "    # print(f\"   - H√¨nh d·∫°ng ƒë·∫ßu v√†o: {input_details.shape}\")\n",
    "    # print(f\"   - Ki·ªÉu d·ªØ li·ªáu ƒë·∫ßu v√†o: {input_details.type}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh ONNX: {e}\")\n",
    "\n",
    "# ==== Mapping classes ====\n",
    "classes = {\n",
    "    1: \"21_Ngay_Yeu_Em\", 2: \"An_Tet_Ben_Con\", 3: \"Bay_Ngot_Ngao\", 4: \"Benh_Vien_Ma\",\n",
    "    5: \"Bi_Mat_Lai_Bi_Mat\", 6: \"Bi_Mat_Trong_Suong_Mu\", 7: \"Bo_Tu_Oan_Gia\", 8: \"Cho_Em_Den_Ngay_Mai\",\n",
    "    9: \"Chu_Tich_Giao_Hang\", 10: \"Chuyen_Tet\", 11: \"Co_Ba_Sai_Gon\", 12: \"Dao_Pho_Va_Piano\",\n",
    "    13: \"Dat_Phuong_Nam\", 14: \"Dia_Dao\", 15: \"Dinh_Menh_Thien_Y\", 16: \"Em_Chua_18\",\n",
    "    17: \"Em_La_Cua_Em\", 18: \"Gai_Gia_Lam_Chieu_3\", 19: \"Gia_Ngheo_Gap_Phat\", 20: \"Hem_Cut\",\n",
    "    21: \"Hoan_Doi\", 22: \"Ke_An_Danh\", 23: \"Ke_An_Hon\", 24: \"Lam_Giau_Voi_Ma\",\n",
    "    25: \"Lat_Mat_1\", 26: \"Lo_Mat\", 27: \"Ma_Da\", 28: \"Mat_Biec\",\n",
    "    29: \"Nhung_Nu_Hon_Ruc_Ro\", 30: \"Oan_Linh__Phan_1\", 31: \"Ong_Ngoai_Tuoi_30\",\n",
    "    32: \"Phap_Su_Tap_Su\", 33: \"Quy_Co_Thua_Ke\", 34: \"Ra_Mat_Gia_Tien\",\n",
    "    35: \"Sieu_Lua_Gap_Sieu_Lay\", 36: \"Sieu_Quay\", 37: \"Sieu_Tro_Ly\",\n",
    "    38: \"Taxi_Em_Ten_Gi\", 39: \"The_Call\", 40: \"Thien_Menh_Anh_Hung\",\n",
    "    41: \"Tieu_Thu_Va_Ba_Dau_Gau\", 42: \"Tren_Ban_Nhau_Duoi_Ban_Muu\"\n",
    "}\n",
    "class_to_idx = {name: idx for idx, name in classes.items()}\n",
    "idx_to_class = {idx: name for name, idx in class_to_idx.items()}\n",
    "\n",
    "# ==== Duy·ªát t·∫≠p test v√† l·∫•y ·∫£nh t·ª´ m·ªói th∆∞ m·ª•c ====\n",
    "y_true = []\n",
    "y_pred = []\n",
    "all_images = []\n",
    "\n",
    "for class_name in os.listdir(test_path):\n",
    "    class_dir = os.path.join(test_path, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "\n",
    "    # L·∫•y danh s√°ch ·∫£nh trong th∆∞ m·ª•c n√†y\n",
    "    image_files = [\n",
    "        os.path.join(class_dir, f)\n",
    "        for f in os.listdir(class_dir)\n",
    "        if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "    ]\n",
    "\n",
    "    # L·∫•y ng·∫´u nhi√™n n ·∫£nh t·ª´ folder (ho·∫∑c √≠t h∆°n n·∫øu kh√¥ng ƒë·ªß)\n",
    "    selected_images = random.sample(image_files, min(n_per_class, len(image_files)))\n",
    "    all_images.extend(selected_images)\n",
    "\n",
    "# ==== D·ª± ƒëo√°n ====\n",
    "for img_path in tqdm(all_images, desc=\"Testing with KNN\"):\n",
    "    try:\n",
    "        folder_name = os.path.basename(os.path.dirname(img_path))\n",
    "        if folder_name not in class_to_idx:\n",
    "            print(f\"‚ùå Folder kh√¥ng h·ª£p l·ªá: {folder_name}\")\n",
    "            continue\n",
    "\n",
    "        img = image.load_img(img_path, target_size=(image_size, image_size))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        # Tr√≠ch ƒë·∫∑c tr∆∞ng v·ªõi ResNet50\n",
    "        feature = model.predict(x, verbose=0)\n",
    "        \n",
    "        if feature.ndim > 2:\n",
    "            feature = feature.reshape(1, -1)\n",
    "        \n",
    "        # V√¨ ch√∫ng ta ƒë·∫£m b·∫£o ƒë·∫ßu v√†o l√† float32 ƒë·ªÉ tr√°nh l·ªói ki·ªÉu d·ªØ li·ªáu\n",
    "        feature = feature.astype(np.float32)\n",
    "\n",
    "        # L·∫•y t√™n ƒë·∫ßu v√†o t·ª´ m√¥ h√¨nh ONNX ƒë·ªÉ ƒë·∫£m b·∫£o ƒë√∫ng\n",
    "        input_name = onnx_session.get_inputs()[0].name\n",
    "        \n",
    "        # D·ª± ƒëo√°n v·ªõi m√¥ h√¨nh ONNX\n",
    "        outputs = onnx_session.run(None, {input_name: feature})\n",
    "        \n",
    "        if outputs[0].ndim == 2:  \n",
    "            pred_label = np.argmax(outputs[0][0]) + 1 \n",
    "        else:\n",
    "            pred_label = outputs[0][0]\n",
    "\n",
    "        y_true.append(class_to_idx[folder_name])\n",
    "        y_pred.append(pred_label)\n",
    "    except Exception as e:\n",
    "        print(f\"L·ªói ·∫£nh {img_path}: {e}\")\n",
    "        print(f\"  H√¨nh d·∫°ng ƒë·∫∑c tr∆∞ng: {feature.shape}, Ki·ªÉu d·ªØ li·ªáu: {feature.dtype}\")\n",
    "\n",
    "# print(f\"H√¨nh d·∫°ng ƒë·∫ßu ra: {[output.shape for output in outputs]}\")\n",
    "# print(f\"Ki·ªÉu ƒë·∫ßu ra: {[output.dtype for output in outputs]}\")\n",
    "# print(f\"Gi√° tr·ªã ƒë·∫ßu ra ƒë·∫ßu ti√™n: {outputs[0][0]}\")\n",
    "\n",
    "# ==== ƒê√°nh gi√° ====\n",
    "if len(y_true) == 0:\n",
    "    print(\"‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ƒë√°nh gi√°!\")\n",
    "else:\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    if y_pred.ndim > 1 and y_pred.shape[1] > 1:\n",
    "        y_pred = np.argmax(y_pred, axis=1) + 1\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "\n",
    "    print(f\"\\n‚úÖ Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"‚úÖ ƒê√∫ng: {np.sum(y_true == y_pred)} / ‚ùå Sai: {np.sum(y_true != y_pred)}\")\n",
    "\n",
    "    # ==== Confusion Matrix ====\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    class_labels = [classes[i] for i in sorted(classes.keys())]\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "    fig, ax = plt.subplots(figsize=(16, 16))\n",
    "    disp.plot(xticks_rotation=90, cmap='Blues', ax=ax, colorbar=False)\n",
    "    plt.title(\"Confusion Matrix (KNN)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(confusion_output_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"\\nüñºÔ∏è Confusion matrix ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o '{confusion_output_path}'\")\n",
    "\n",
    "    # ==== Classification Report ====\n",
    "    print(\"\\nüìÑ Classification Report:\")\n",
    "    report = classification_report(\n",
    "        y_true, y_pred, target_names=class_labels,\n",
    "        digits=2, output_dict=True\n",
    "    )\n",
    "\n",
    "    # Chuy·ªÉn b√°o c√°o ph√¢n lo·∫°i th√†nh DataFrame\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    if \"accuracy\" not in report_df.columns:\n",
    "        report_df[\"accuracy\"] = accuracy\n",
    "    print(report_df[[\"precision\", \"recall\", \"f1-score\", \"accuracy\"]])\n",
    "\n",
    "    # Hi·ªÉn th·ªã c√°c tham s·ªë chung cho to√†n b·ªô ch∆∞∆°ng tr√¨nh\n",
    "    avg_precision = np.mean(report_df['precision'])\n",
    "    avg_recall = np.mean(report_df['recall'])\n",
    "    avg_f1 = np.mean(report_df['f1-score'])\n",
    "\n",
    "    print(\"\\nüìù C√°c tham s·ªë ƒë√°nh gi√° chung:\")\n",
    "    print(f\"  - Precision: {avg_precision:.2f}\")\n",
    "    print(f\"  - Recall: {avg_recall:.2f}\")\n",
    "    print(f\"  - F1-score: {avg_f1:.2f}\")\n",
    "    print(f\"  - Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # L∆∞u b√°o c√°o chi ti·∫øt v√†o t·ªáp CSV\n",
    "    report_df.to_csv(csv_output_path, index=True)\n",
    "    print(f\"\\nüìä B√°o c√°o ph√¢n lo·∫°i ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o '{csv_output_path}'\")\n",
    "\n",
    "    # L∆∞u c√°c tham s·ªë ƒë√°nh gi√° chung v√†o t·ªáp CSV\n",
    "    evaluation_metrics = {\n",
    "        'precision': avg_precision,\n",
    "        'recall': avg_recall,\n",
    "        'f1-score': avg_f1,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "\n",
    "    evaluation_df = pd.DataFrame([evaluation_metrics])\n",
    "    evaluation_df.to_csv('evaluation_metrics_knn.csv', index=False)\n",
    "    print(f\"\\nüìä C√°c tham s·ªë ƒë√°nh gi√° chung ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'evaluation_metrics_knn.csv'\")\n",
    "\n",
    "    # L∆∞u c·∫£ b√°o c√°o ph√¢n lo·∫°i v√† c√°c tham s·ªë chung v√†o m·ªôt t·ªáp CSV\n",
    "    final_df = report_df.copy()\n",
    "    final_df['average_precision'] = avg_precision\n",
    "    final_df['average_recall'] = avg_recall\n",
    "    final_df['average_f1-score'] = avg_f1\n",
    "    final_df['average_accuracy'] = accuracy\n",
    "    final_df.to_csv('final_classification_report_knn.csv', index=True)\n",
    "    print(f\"\\nüìä B√°o c√°o ph√¢n lo·∫°i cu·ªëi c√πng ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'final_classification_report_knn.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet50 + FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:08:39.260816Z",
     "iopub.status.busy": "2025-05-10T13:08:39.260089Z",
     "iopub.status.idle": "2025-05-10T13:09:54.489943Z",
     "shell.execute_reply": "2025-05-10T13:09:54.489157Z",
     "shell.execute_reply.started": "2025-05-10T13:08:39.260781Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|          | 0/312 [00:00<?, ?it/s]I0000 00:00:1746882522.517808      31 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 312/312 [01:12<00:00,  4.33it/s]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# S·ªë batch\n",
    "num_batches = tf.data.experimental.cardinality(train_df).numpy()\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# Kh·ªüi t·∫°o model trong context c·ªßa strategy\n",
    "with strategy.scope():\n",
    "    base_model_resnet50 = ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg',\n",
    "        input_shape=(image_size, image_size, 3)\n",
    "    )\n",
    "\n",
    "# N∆°i l∆∞u ƒë·∫∑c tr∆∞ng v√† nh√£n\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "# L·∫∑p qua t·ª´ng batch\n",
    "for images, labels in tqdm(train_df, total=num_batches, desc=\"Extracting features\"):\n",
    "    images_pp = preprocess_input(images)\n",
    "    features_batch = base_model_resnet50(images_pp, training=False)\n",
    "    all_features.append(features_batch.numpy())\n",
    "    all_labels.append(labels.numpy())\n",
    "\n",
    "# ƒê√°nh nh√£n ·ª©ng v·ªõi ƒë·∫∑c tr∆∞ng\n",
    "features_array = np.concatenate(all_features, axis=0)\n",
    "labels_array = np.concatenate(all_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:10:11.228204Z",
     "iopub.status.busy": "2025-05-10T13:10:11.227943Z",
     "iopub.status.idle": "2025-05-10T13:10:11.899661Z",
     "shell.execute_reply": "2025-05-10T13:10:11.898904Z",
     "shell.execute_reply.started": "2025-05-10T13:10:11.228188Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ th√™m 39833 vector v√†o FAISS index.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "# K√≠ch th∆∞·ªõc vector ƒë·∫∑c tr∆∞ng\n",
    "d = features_array.shape[1]  \n",
    "\n",
    "# Kh·ªüi t·∫°o index\n",
    "index = faiss.IndexFlatL2(d)  # D√πng kho·∫£ng c√°ch Euclidean\n",
    "\n",
    "# Th√™m c√°c vector v√†o index\n",
    "index.add(features_array.astype('float32'))\n",
    "print(\"ƒê√£ th√™m\", index.ntotal, \"vector v√†o FAISS index.\")\n",
    "\n",
    "faiss.write_index(index, \"faiss_features.index\")\n",
    "np.save(\"faiss_labels.npy\", labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:10:28.309080Z",
     "iopub.status.busy": "2025-05-10T13:10:28.308815Z",
     "iopub.status.idle": "2025-05-10T13:10:28.659179Z",
     "shell.execute_reply": "2025-05-10T13:10:28.658379Z",
     "shell.execute_reply.started": "2025-05-10T13:10:28.309060Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ƒê·ªçc l·∫°i FAISS index v√† nh√£n\n",
    "index = faiss.read_index(\"faiss_features.index\")\n",
    "labels_array = np.load(\"faiss_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-10T13:15:53.453808Z",
     "iopub.status.busy": "2025-05-10T13:15:53.453260Z",
     "iopub.status.idle": "2025-05-10T13:19:28.404333Z",
     "shell.execute_reply": "2025-05-10T13:19:28.403687Z",
     "shell.execute_reply.started": "2025-05-10T13:15:53.453782Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# C√†i ƒë·∫∑t c√°c tham s·ªë\n",
    "image_size = 128\n",
    "test_path = \"/kaggle/input/frames-film-vietnam-dataset/Frame_Test\"\n",
    "index_path = \"faiss_features.index\" \n",
    "label_path = \"faiss_labels.npy\"      \n",
    "confusion_output_path = \"confusion_matrix_faiss.jpg\"\n",
    "csv_output_path = \"classification_report_faiss.csv\"\n",
    "n_per_class = 50\n",
    "\n",
    "# ==== Load m√¥ h√¨nh v√† FAISS index ====\n",
    "# Load m√¥ h√¨nh ResNet50 (ho·∫∑c InceptionV3)\n",
    "model = ResNet50(include_top=False, weights='imagenet', pooling='avg', input_shape=(image_size, image_size, 3))\n",
    "\n",
    "# Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n FAISS index v√† labels\n",
    "if not os.path.exists(index_path):\n",
    "    print(f\"‚ùå Kh√¥ng t√¨m th·∫•y FAISS index t·∫°i: {index_path}\")\n",
    "if not os.path.exists(label_path):\n",
    "    print(f\"‚ùå Kh√¥ng t√¨m th·∫•y nh√£n t·∫°i: {label_path}\")\n",
    "\n",
    "# Load FAISS index v√† labels\n",
    "try:\n",
    "    # Load index tr·ª±c ti·∫øp cho CPU\n",
    "    index = faiss.read_index(index_path)\n",
    "\n",
    "    # Load labels\n",
    "    index_labels = np.load(label_path)\n",
    "\n",
    "    print(f\"‚úÖ FAISS index ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!\")\n",
    "    print(f\"   - S·ªë l∆∞·ª£ng vectors: {index.ntotal}\")\n",
    "    print(f\"   - K√≠ch th∆∞·ªõc vector: {index.d}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªói khi t·∫£i FAISS index: {e}\")\n",
    "\n",
    "# ==== Mapping classes ====\n",
    "classes = {\n",
    "    1: \"21_Ngay_Yeu_Em\", 2: \"An_Tet_Ben_Con\", 3: \"Bay_Ngot_Ngao\", 4: \"Benh_Vien_Ma\",\n",
    "    5: \"Bi_Mat_Lai_Bi_Mat\", 6: \"Bi_Mat_Trong_Suong_Mu\", 7: \"Bo_Tu_Oan_Gia\", 8: \"Cho_Em_Den_Ngay_Mai\",\n",
    "    9: \"Chu_Tich_Giao_Hang\", 10: \"Chuyen_Tet\", 11: \"Co_Ba_Sai_Gon\", 12: \"Dao_Pho_Va_Piano\",\n",
    "    13: \"Dat_Phuong_Nam\", 14: \"Dia_Dao\", 15: \"Dinh_Menh_Thien_Y\", 16: \"Em_Chua_18\",\n",
    "    17: \"Em_La_Cua_Em\", 18: \"Gai_Gia_Lam_Chieu_3\", 19: \"Gia_Ngheo_Gap_Phat\", 20: \"Hem_Cut\",\n",
    "    21: \"Hoan_Doi\", 22: \"Ke_An_Danh\", 23: \"Ke_An_Hon\", 24: \"Lam_Giau_Voi_Ma\",\n",
    "    25: \"Lat_Mat_1\", 26: \"Lo_Mat\", 27: \"Ma_Da\", 28: \"Mat_Biec\",\n",
    "    29: \"Nhung_Nu_Hon_Ruc_Ro\", 30: \"Oan_Linh__Phan_1\", 31: \"Ong_Ngoai_Tuoi_30\",\n",
    "    32: \"Phap_Su_Tap_Su\", 33: \"Quy_Co_Thua_Ke\", 34: \"Ra_Mat_Gia_Tien\",\n",
    "    35: \"Sieu_Lua_Gap_Sieu_Lay\", 36: \"Sieu_Quay\", 37: \"Sieu_Tro_Ly\",\n",
    "    38: \"Taxi_Em_Ten_Gi\", 39: \"The_Call\", 40: \"Thien_Menh_Anh_Hung\",\n",
    "    41: \"Tieu_Thu_Va_Ba_Dau_Gau\", 42: \"Tren_Ban_Nhau_Duoi_Ban_Muu\"\n",
    "}\n",
    "class_to_idx = {name: idx for idx, name in classes.items()}\n",
    "idx_to_class = {idx: name for name, idx in class_to_idx.items()}\n",
    "\n",
    "# ==== Duy·ªát t·∫≠p test v√† l·∫•y ·∫£nh t·ª´ m·ªói th∆∞ m·ª•c ====\n",
    "y_true = []\n",
    "y_pred = []\n",
    "all_images = []\n",
    "for class_name in os.listdir(test_path):\n",
    "    class_dir = os.path.join(test_path, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "    # L·∫•y danh s√°ch ·∫£nh trong th∆∞ m·ª•c n√†y\n",
    "    image_files = [\n",
    "        os.path.join(class_dir, f)\n",
    "        for f in os.listdir(class_dir)\n",
    "        if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "    ]\n",
    "    # L·∫•y ng·∫´u nhi√™n n ·∫£nh t·ª´ folder (ho·∫∑c √≠t h∆°n n·∫øu kh√¥ng ƒë·ªß)\n",
    "    selected_images = random.sample(image_files, min(n_per_class, len(image_files)))\n",
    "    all_images.extend(selected_images)\n",
    "\n",
    "# ==== D·ª± ƒëo√°n ====\n",
    "for img_path in tqdm(all_images, desc=\"Testing with FAISS\"):\n",
    "    try:\n",
    "        folder_name = os.path.basename(os.path.dirname(img_path))\n",
    "        if folder_name not in class_to_idx:\n",
    "            print(f\"‚ùå Folder kh√¥ng h·ª£p l·ªá: {folder_name}\")\n",
    "            continue\n",
    "        img = image.load_img(img_path, target_size=(image_size, image_size))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        # Tr√≠ch ƒë·∫∑c tr∆∞ng v·ªõi m√¥ h√¨nh\n",
    "        feature = model.predict(x, verbose=0)\n",
    "        \n",
    "        # ƒê·∫£m b·∫£o ƒë·∫∑c tr∆∞ng c√≥ ƒë·ªãnh d·∫°ng ph√π h·ª£p\n",
    "        feature = feature.astype(np.float32)\n",
    "        \n",
    "        # T√¨m ki·∫øm k=1 ƒëi·ªÉm g·∫ßn nh·∫•t trong FAISS index\n",
    "        D, I = index.search(feature, 1)\n",
    "        \n",
    "        # L·∫•y nh√£n d·ª± ƒëo√°n t·ª´ FAISS\n",
    "        pred_label_data = index_labels[I[0][0]]\n",
    "        if isinstance(pred_label_data, (np.ndarray, list)) and len(pred_label_data) > 1:\n",
    "            pred_label = int(np.argmax(pred_label_data)) + 1\n",
    "        else:\n",
    "            pred_label = int(pred_label_data)\n",
    "\n",
    "        y_true.append(class_to_idx[folder_name])\n",
    "        y_pred.append(pred_label)\n",
    "    except Exception as e:\n",
    "        print(f\"L·ªói ·∫£nh {img_path}: {e}\")\n",
    "        print(f\"  H√¨nh d·∫°ng ƒë·∫∑c tr∆∞ng: {feature.shape}, Ki·ªÉu d·ªØ li·ªáu: {feature.dtype}\")\n",
    "\n",
    "# ==== ƒê√°nh gi√° ====\n",
    "if len(y_true) == 0:\n",
    "    print(\"‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ƒë√°nh gi√°!\")\n",
    "else:\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    print(f\"\\n‚úÖ Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"‚úÖ ƒê√∫ng: {np.sum(y_true == y_pred)} / ‚ùå Sai: {np.sum(y_true != y_pred)}\")\n",
    "    \n",
    "    # ==== Confusion Matrix ====\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    class_labels = [classes[i] for i in sorted(classes.keys())]\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "    fig, ax = plt.subplots(figsize=(16, 16))\n",
    "    disp.plot(xticks_rotation=90, cmap='Blues', ax=ax, colorbar=False)\n",
    "    plt.title(\"Confusion Matrix (FAISS)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(confusion_output_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"\\nüñºÔ∏è Confusion matrix ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o '{confusion_output_path}'\")\n",
    "    \n",
    "    # ==== Classification Report ====\n",
    "    print(\"\\nüìÑ Classification Report:\")\n",
    "    report = classification_report(\n",
    "        y_true, y_pred, target_names=class_labels,\n",
    "        digits=2, output_dict=True\n",
    "    )\n",
    "    # Chuy·ªÉn b√°o c√°o ph√¢n lo·∫°i th√†nh DataFrame\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    if \"accuracy\" not in report_df.columns:\n",
    "        report_df[\"accuracy\"] = accuracy\n",
    "    print(report_df[[\"precision\", \"recall\", \"f1-score\", \"accuracy\"]])\n",
    "    \n",
    "    # Hi·ªÉn th·ªã c√°c tham s·ªë chung cho to√†n b·ªô ch∆∞∆°ng tr√¨nh\n",
    "    avg_precision = np.mean(report_df['precision'])\n",
    "    avg_recall = np.mean(report_df['recall'])\n",
    "    avg_f1 = np.mean(report_df['f1-score'])\n",
    "    print(\"\\nüìù C√°c tham s·ªë ƒë√°nh gi√° chung:\")\n",
    "    print(f\"  - Precision: {avg_precision:.2f}\")\n",
    "    print(f\"  - Recall: {avg_recall:.2f}\")\n",
    "    print(f\"  - F1-score: {avg_f1:.2f}\")\n",
    "    print(f\"  - Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # L∆∞u b√°o c√°o chi ti·∫øt v√†o t·ªáp CSV\n",
    "    report_df.to_csv(csv_output_path, index=True)\n",
    "    print(f\"\\nüìä B√°o c√°o ph√¢n lo·∫°i ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o '{csv_output_path}'\")\n",
    "    \n",
    "    # L∆∞u c√°c tham s·ªë ƒë√°nh gi√° chung v√†o t·ªáp CSV\n",
    "    evaluation_metrics = {\n",
    "        'precision': avg_precision,\n",
    "        'recall': avg_recall,\n",
    "        'f1-score': avg_f1,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "    evaluation_df = pd.DataFrame([evaluation_metrics])\n",
    "    evaluation_df.to_csv('evaluation_metrics_faiss.csv', index=False)\n",
    "    print(f\"\\nüìä C√°c tham s·ªë ƒë√°nh gi√° chung ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'evaluation_metrics_faiss.csv'\")\n",
    "    \n",
    "    # L∆∞u c·∫£ b√°o c√°o ph√¢n lo·∫°i v√† c√°c tham s·ªë chung v√†o m·ªôt t·ªáp CSV\n",
    "    final_df = report_df.copy()\n",
    "    final_df['average_precision'] = avg_precision\n",
    "    final_df['average_recall'] = avg_recall\n",
    "    final_df['average_f1-score'] = avg_f1\n",
    "    final_df['average_accuracy'] = accuracy\n",
    "    final_df.to_csv('final_classification_report_faiss.csv', index=True)\n",
    "    print(f\"\\nüìä B√°o c√°o ph√¢n lo·∫°i cu·ªëi c√πng ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'final_classification_report_faiss.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNetB4 + FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:41:14.367216Z",
     "iopub.status.busy": "2025-05-10T13:41:14.366524Z",
     "iopub.status.idle": "2025-05-10T13:43:50.497088Z",
     "shell.execute_reply": "2025-05-10T13:43:50.496329Z",
     "shell.execute_reply.started": "2025-05-10T13:41:14.367193Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features with EfficientNetB4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 312/312 [02:33<00:00,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "# S·ªë batch\n",
    "num_batches = tf.data.experimental.cardinality(train_df).numpy()\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# Kh·ªüi t·∫°o EfficientNetB4 trong context c·ªßa strategy\n",
    "with strategy.scope():\n",
    "    base_model_efficientnetb4 = EfficientNetB4(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg',\n",
    "        input_shape=(image_size, image_size, 3)\n",
    "    )\n",
    "\n",
    "# N∆°i l∆∞u ƒë·∫∑c tr∆∞ng v√† nh√£n\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "# L·∫∑p qua t·ª´ng batch\n",
    "for images, labels in tqdm(train_df, total=num_batches, desc=\"Extracting features with EfficientNetB4\"):\n",
    "    images_pp = preprocess_input(images)\n",
    "    features_batch = base_model_efficientnetb4(images_pp, training=False)\n",
    "    all_features.append(features_batch.numpy())\n",
    "    all_labels.append(labels.numpy())\n",
    "\n",
    "# K·∫øt h·ª£p ƒë·∫∑c tr∆∞ng v√† nh√£n\n",
    "features_array = np.concatenate(all_features, axis=0)\n",
    "labels_array = np.concatenate(all_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:43:53.558269Z",
     "iopub.status.busy": "2025-05-10T13:43:53.557981Z",
     "iopub.status.idle": "2025-05-10T13:43:54.158357Z",
     "shell.execute_reply": "2025-05-10T13:43:54.157768Z",
     "shell.execute_reply.started": "2025-05-10T13:43:53.558250Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ th√™m 39833 vector v√†o FAISS index.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "# K√≠ch th∆∞·ªõc vector ƒë·∫∑c tr∆∞ng\n",
    "d = features_array.shape[1]  \n",
    "\n",
    "# Kh·ªüi t·∫°o index\n",
    "index = faiss.IndexFlatL2(d)  # D√πng kho·∫£ng c√°ch Euclidean\n",
    "\n",
    "# Th√™m c√°c vector v√†o index\n",
    "index.add(features_array.astype('float32'))\n",
    "print(\"ƒê√£ th√™m\", index.ntotal, \"vector v√†o FAISS index.\")\n",
    "\n",
    "faiss.write_index(index, \"faiss_features.index\")\n",
    "np.save(\"faiss_labels.npy\", labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:44:01.654138Z",
     "iopub.status.busy": "2025-05-10T13:44:01.653880Z",
     "iopub.status.idle": "2025-05-10T13:44:01.962370Z",
     "shell.execute_reply": "2025-05-10T13:44:01.961578Z",
     "shell.execute_reply.started": "2025-05-10T13:44:01.654121Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ƒê·ªçc l·∫°i FAISS index v√† nh√£n\n",
    "index = faiss.read_index(\"faiss_features.index\")\n",
    "labels_array = np.load(\"faiss_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-10T13:44:04.590184Z",
     "iopub.status.busy": "2025-05-10T13:44:04.589643Z",
     "iopub.status.idle": "2025-05-10T13:47:50.348978Z",
     "shell.execute_reply": "2025-05-10T13:47:50.348328Z",
     "shell.execute_reply.started": "2025-05-10T13:44:04.590158Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# C√†i ƒë·∫∑t c√°c tham s·ªë\n",
    "image_size = 128\n",
    "test_path = \"/kaggle/input/frames-film-vietnam-dataset/Frame_Test\"\n",
    "index_path = \"faiss_features.index\" \n",
    "label_path = \"faiss_labels.npy\"      \n",
    "confusion_output_path = \"confusion_matrix_faiss.jpg\"\n",
    "csv_output_path = \"classification_report_faiss.csv\"\n",
    "n_per_class = 50\n",
    "\n",
    "# ==== Load m√¥ h√¨nh v√† FAISS index ====\n",
    "model = EfficientNetB4(include_top=False, weights='imagenet', pooling='avg', input_shape=(image_size, image_size, 3))\n",
    "\n",
    "# Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n FAISS index v√† labels\n",
    "if not os.path.exists(index_path):\n",
    "    print(f\"‚ùå Kh√¥ng t√¨m th·∫•y FAISS index t·∫°i: {index_path}\")\n",
    "if not os.path.exists(label_path):\n",
    "    print(f\"‚ùå Kh√¥ng t√¨m th·∫•y nh√£n t·∫°i: {label_path}\")\n",
    "\n",
    "# Load FAISS index v√† labels\n",
    "try:\n",
    "    # Load index tr·ª±c ti·∫øp cho CPU\n",
    "    index = faiss.read_index(index_path)\n",
    "\n",
    "    # Load labels\n",
    "    index_labels = np.load(label_path)\n",
    "\n",
    "    print(f\"‚úÖ FAISS index ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!\")\n",
    "    print(f\"   - S·ªë l∆∞·ª£ng vectors: {index.ntotal}\")\n",
    "    print(f\"   - K√≠ch th∆∞·ªõc vector: {index.d}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªói khi t·∫£i FAISS index: {e}\")\n",
    "\n",
    "# ==== Mapping classes ====\n",
    "classes = {\n",
    "    1: \"21_Ngay_Yeu_Em\", 2: \"An_Tet_Ben_Con\", 3: \"Bay_Ngot_Ngao\", 4: \"Benh_Vien_Ma\",\n",
    "    5: \"Bi_Mat_Lai_Bi_Mat\", 6: \"Bi_Mat_Trong_Suong_Mu\", 7: \"Bo_Tu_Oan_Gia\", 8: \"Cho_Em_Den_Ngay_Mai\",\n",
    "    9: \"Chu_Tich_Giao_Hang\", 10: \"Chuyen_Tet\", 11: \"Co_Ba_Sai_Gon\", 12: \"Dao_Pho_Va_Piano\",\n",
    "    13: \"Dat_Phuong_Nam\", 14: \"Dia_Dao\", 15: \"Dinh_Menh_Thien_Y\", 16: \"Em_Chua_18\",\n",
    "    17: \"Em_La_Cua_Em\", 18: \"Gai_Gia_Lam_Chieu_3\", 19: \"Gia_Ngheo_Gap_Phat\", 20: \"Hem_Cut\",\n",
    "    21: \"Hoan_Doi\", 22: \"Ke_An_Danh\", 23: \"Ke_An_Hon\", 24: \"Lam_Giau_Voi_Ma\",\n",
    "    25: \"Lat_Mat_1\", 26: \"Lo_Mat\", 27: \"Ma_Da\", 28: \"Mat_Biec\",\n",
    "    29: \"Nhung_Nu_Hon_Ruc_Ro\", 30: \"Oan_Linh__Phan_1\", 31: \"Ong_Ngoai_Tuoi_30\",\n",
    "    32: \"Phap_Su_Tap_Su\", 33: \"Quy_Co_Thua_Ke\", 34: \"Ra_Mat_Gia_Tien\",\n",
    "    35: \"Sieu_Lua_Gap_Sieu_Lay\", 36: \"Sieu_Quay\", 37: \"Sieu_Tro_Ly\",\n",
    "    38: \"Taxi_Em_Ten_Gi\", 39: \"The_Call\", 40: \"Thien_Menh_Anh_Hung\",\n",
    "    41: \"Tieu_Thu_Va_Ba_Dau_Gau\", 42: \"Tren_Ban_Nhau_Duoi_Ban_Muu\"\n",
    "}\n",
    "class_to_idx = {name: idx for idx, name in classes.items()}\n",
    "idx_to_class = {idx: name for name, idx in class_to_idx.items()}\n",
    "\n",
    "# ==== Duy·ªát t·∫≠p test v√† l·∫•y ·∫£nh t·ª´ m·ªói th∆∞ m·ª•c ====\n",
    "y_true = []\n",
    "y_pred = []\n",
    "all_images = []\n",
    "for class_name in os.listdir(test_path):\n",
    "    class_dir = os.path.join(test_path, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "    # L·∫•y danh s√°ch ·∫£nh trong th∆∞ m·ª•c n√†y\n",
    "    image_files = [\n",
    "        os.path.join(class_dir, f)\n",
    "        for f in os.listdir(class_dir)\n",
    "        if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "    ]\n",
    "    # L·∫•y ng·∫´u nhi√™n n ·∫£nh t·ª´ folder (ho·∫∑c √≠t h∆°n n·∫øu kh√¥ng ƒë·ªß)\n",
    "    selected_images = random.sample(image_files, min(n_per_class, len(image_files)))\n",
    "    all_images.extend(selected_images)\n",
    "\n",
    "# ==== D·ª± ƒëo√°n ====\n",
    "for img_path in tqdm(all_images, desc=\"Testing with FAISS\"):\n",
    "    try:\n",
    "        folder_name = os.path.basename(os.path.dirname(img_path))\n",
    "        if folder_name not in class_to_idx:\n",
    "            print(f\"‚ùå Folder kh√¥ng h·ª£p l·ªá: {folder_name}\")\n",
    "            continue\n",
    "        img = image.load_img(img_path, target_size=(image_size, image_size))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        # Tr√≠ch ƒë·∫∑c tr∆∞ng v·ªõi m√¥ h√¨nh\n",
    "        feature = model.predict(x, verbose=0)\n",
    "        \n",
    "        # ƒê·∫£m b·∫£o ƒë·∫∑c tr∆∞ng c√≥ ƒë·ªãnh d·∫°ng ph√π h·ª£p\n",
    "        feature = feature.astype(np.float32)\n",
    "        \n",
    "        # T√¨m ki·∫øm k=1 ƒëi·ªÉm g·∫ßn nh·∫•t trong FAISS index\n",
    "        D, I = index.search(feature, 1)\n",
    "        \n",
    "        # L·∫•y nh√£n d·ª± ƒëo√°n t·ª´ FAISS\n",
    "        pred_label_data = index_labels[I[0][0]]\n",
    "        if isinstance(pred_label_data, (np.ndarray, list)) and len(pred_label_data) > 1:\n",
    "            pred_label = int(np.argmax(pred_label_data)) + 1\n",
    "        else:\n",
    "            pred_label = int(pred_label_data)\n",
    "\n",
    "        y_true.append(class_to_idx[folder_name])\n",
    "        y_pred.append(pred_label)\n",
    "    except Exception as e:\n",
    "        print(f\"L·ªói ·∫£nh {img_path}: {e}\")\n",
    "        print(f\"  H√¨nh d·∫°ng ƒë·∫∑c tr∆∞ng: {feature.shape}, Ki·ªÉu d·ªØ li·ªáu: {feature.dtype}\")\n",
    "\n",
    "# ==== ƒê√°nh gi√° ====\n",
    "if len(y_true) == 0:\n",
    "    print(\"‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ƒë√°nh gi√°!\")\n",
    "else:\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    print(f\"\\n‚úÖ Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"‚úÖ ƒê√∫ng: {np.sum(y_true == y_pred)} / ‚ùå Sai: {np.sum(y_true != y_pred)}\")\n",
    "    \n",
    "    # ==== Confusion Matrix ====\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    class_labels = [classes[i] for i in sorted(classes.keys())]\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "    fig, ax = plt.subplots(figsize=(16, 16))\n",
    "    disp.plot(xticks_rotation=90, cmap='Blues', ax=ax, colorbar=False)\n",
    "    plt.title(\"Confusion Matrix (FAISS)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(confusion_output_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"\\nüñºÔ∏è Confusion matrix ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o '{confusion_output_path}'\")\n",
    "    \n",
    "    # ==== Classification Report ====\n",
    "    print(\"\\nüìÑ Classification Report:\")\n",
    "    report = classification_report(\n",
    "        y_true, y_pred, target_names=class_labels,\n",
    "        digits=2, output_dict=True\n",
    "    )\n",
    "    # Chuy·ªÉn b√°o c√°o ph√¢n lo·∫°i th√†nh DataFrame\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    if \"accuracy\" not in report_df.columns:\n",
    "        report_df[\"accuracy\"] = accuracy\n",
    "    print(report_df[[\"precision\", \"recall\", \"f1-score\", \"accuracy\"]])\n",
    "    \n",
    "    # Hi·ªÉn th·ªã c√°c tham s·ªë chung cho to√†n b·ªô ch∆∞∆°ng tr√¨nh\n",
    "    avg_precision = np.mean(report_df['precision'])\n",
    "    avg_recall = np.mean(report_df['recall'])\n",
    "    avg_f1 = np.mean(report_df['f1-score'])\n",
    "    print(\"\\nüìù C√°c tham s·ªë ƒë√°nh gi√° chung:\")\n",
    "    print(f\"  - Precision: {avg_precision:.2f}\")\n",
    "    print(f\"  - Recall: {avg_recall:.2f}\")\n",
    "    print(f\"  - F1-score: {avg_f1:.2f}\")\n",
    "    print(f\"  - Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # L∆∞u b√°o c√°o chi ti·∫øt v√†o t·ªáp CSV\n",
    "    report_df.to_csv(csv_output_path, index=True)\n",
    "    print(f\"\\nüìä B√°o c√°o ph√¢n lo·∫°i ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o '{csv_output_path}'\")\n",
    "    \n",
    "    # L∆∞u c√°c tham s·ªë ƒë√°nh gi√° chung v√†o t·ªáp CSV\n",
    "    evaluation_metrics = {\n",
    "        'precision': avg_precision,\n",
    "        'recall': avg_recall,\n",
    "        'f1-score': avg_f1,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "    evaluation_df = pd.DataFrame([evaluation_metrics])\n",
    "    evaluation_df.to_csv('evaluation_metrics_faiss.csv', index=False)\n",
    "    print(f\"\\nüìä C√°c tham s·ªë ƒë√°nh gi√° chung ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'evaluation_metrics_faiss.csv'\")\n",
    "    \n",
    "    # L∆∞u c·∫£ b√°o c√°o ph√¢n lo·∫°i v√† c√°c tham s·ªë chung v√†o m·ªôt t·ªáp CSV\n",
    "    final_df = report_df.copy()\n",
    "    final_df['average_precision'] = avg_precision\n",
    "    final_df['average_recall'] = avg_recall\n",
    "    final_df['average_f1-score'] = avg_f1\n",
    "    final_df['average_accuracy'] = accuracy\n",
    "    final_df.to_csv('final_classification_report_faiss.csv', index=True)\n",
    "    print(f\"\\nüìä B√°o c√°o ph√¢n lo·∫°i cu·ªëi c√πng ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'final_classification_report_faiss.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionV3 + FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:49:34.579594Z",
     "iopub.status.busy": "2025-05-10T13:49:34.579303Z",
     "iopub.status.idle": "2025-05-10T13:51:07.470453Z",
     "shell.execute_reply": "2025-05-10T13:51:07.469583Z",
     "shell.execute_reply.started": "2025-05-10T13:49:34.579575Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m87910968/87910968\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features with InceptionV3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 312/312 [01:29<00:00,  3.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "# Gi·∫£ s·ª≠ bi·∫øn train_df l√† tf.data.Dataset ƒë√£ chu·∫©n h√≥a v√† batch ƒë√∫ng\n",
    "num_batches = tf.data.experimental.cardinality(train_df).numpy()\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# Kh·ªüi t·∫°o InceptionV3 trong context c·ªßa strategy\n",
    "with strategy.scope():\n",
    "    base_model_inceptionv3 = InceptionV3(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg',\n",
    "        input_shape=(image_size, image_size, 3)\n",
    "    )\n",
    "\n",
    "# Tr√≠ch ƒë·∫∑c tr∆∞ng v√† nh√£n\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "for images, labels in tqdm(train_df, total=num_batches, desc=\"Extracting features with InceptionV3\"):\n",
    "    images_pp = preprocess_input(images)\n",
    "    features_batch = base_model_inceptionv3(images_pp, training=False)\n",
    "    all_features.append(features_batch.numpy())\n",
    "    all_labels.append(labels.numpy())\n",
    "\n",
    "features_array = np.concatenate(all_features, axis=0)   \n",
    "labels_array = np.concatenate(all_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T13:52:00.842383Z",
     "iopub.status.busy": "2025-05-10T13:52:00.841673Z",
     "iopub.status.idle": "2025-05-10T13:52:01.517223Z",
     "shell.execute_reply": "2025-05-10T13:52:01.516639Z",
     "shell.execute_reply.started": "2025-05-10T13:52:00.842355Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ th√™m 39833 vector v√†o FAISS index.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "# K√≠ch th∆∞·ªõc vector ƒë·∫∑c tr∆∞ng\n",
    "d = features_array.shape[1]  \n",
    "\n",
    "# Kh·ªüi t·∫°o index\n",
    "index = faiss.IndexFlatL2(d)  # D√πng kho·∫£ng c√°ch Euclidean\n",
    "\n",
    "# Th√™m c√°c vector v√†o index\n",
    "index.add(features_array.astype('float32'))\n",
    "print(\"ƒê√£ th√™m\", index.ntotal, \"vector v√†o FAISS index.\")\n",
    "\n",
    "faiss.write_index(index, \"faiss_features.index\")\n",
    "np.save(\"faiss_labels.npy\", labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ƒê·ªçc l·∫°i FAISS index v√† nh√£n\n",
    "index = faiss.read_index(\"faiss_features.index\")\n",
    "labels_array = np.load(\"faiss_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-05-10T13:52:24.254872Z",
     "iopub.status.busy": "2025-05-10T13:52:24.254330Z",
     "iopub.status.idle": "2025-05-10T13:56:14.868810Z",
     "shell.execute_reply": "2025-05-10T13:56:14.868202Z",
     "shell.execute_reply.started": "2025-05-10T13:52:24.254849Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# C√†i ƒë·∫∑t c√°c tham s·ªë\n",
    "image_size = 128\n",
    "test_path = \"/kaggle/input/frames-film-vietnam-dataset/Frame_Test\"\n",
    "index_path = \"faiss_features.index\" \n",
    "label_path = \"faiss_labels.npy\"      \n",
    "confusion_output_path = \"confusion_matrix_faiss.jpg\"\n",
    "csv_output_path = \"classification_report_faiss.csv\"\n",
    "n_per_class = 50\n",
    "\n",
    "# ==== Load m√¥ h√¨nh v√† FAISS index ====\n",
    "model = InceptionV3(include_top=False, weights='imagenet', pooling='avg', input_shape=(image_size, image_size, 3))\n",
    "\n",
    "# Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n FAISS index v√† labels\n",
    "if not os.path.exists(index_path):\n",
    "    print(f\"‚ùå Kh√¥ng t√¨m th·∫•y FAISS index t·∫°i: {index_path}\")\n",
    "if not os.path.exists(label_path):\n",
    "    print(f\"‚ùå Kh√¥ng t√¨m th·∫•y nh√£n t·∫°i: {label_path}\")\n",
    "\n",
    "# Load FAISS index v√† labels\n",
    "try:\n",
    "    # Load index tr·ª±c ti·∫øp cho CPU\n",
    "    index = faiss.read_index(index_path)\n",
    "\n",
    "    # Load labels\n",
    "    index_labels = np.load(label_path)\n",
    "\n",
    "    print(f\"‚úÖ FAISS index ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!\")\n",
    "    print(f\"   - S·ªë l∆∞·ª£ng vectors: {index.ntotal}\")\n",
    "    print(f\"   - K√≠ch th∆∞·ªõc vector: {index.d}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªói khi t·∫£i FAISS index: {e}\")\n",
    "\n",
    "# ==== Mapping classes ====\n",
    "classes = {\n",
    "    1: \"21_Ngay_Yeu_Em\", 2: \"An_Tet_Ben_Con\", 3: \"Bay_Ngot_Ngao\", 4: \"Benh_Vien_Ma\",\n",
    "    5: \"Bi_Mat_Lai_Bi_Mat\", 6: \"Bi_Mat_Trong_Suong_Mu\", 7: \"Bo_Tu_Oan_Gia\", 8: \"Cho_Em_Den_Ngay_Mai\",\n",
    "    9: \"Chu_Tich_Giao_Hang\", 10: \"Chuyen_Tet\", 11: \"Co_Ba_Sai_Gon\", 12: \"Dao_Pho_Va_Piano\",\n",
    "    13: \"Dat_Phuong_Nam\", 14: \"Dia_Dao\", 15: \"Dinh_Menh_Thien_Y\", 16: \"Em_Chua_18\",\n",
    "    17: \"Em_La_Cua_Em\", 18: \"Gai_Gia_Lam_Chieu_3\", 19: \"Gia_Ngheo_Gap_Phat\", 20: \"Hem_Cut\",\n",
    "    21: \"Hoan_Doi\", 22: \"Ke_An_Danh\", 23: \"Ke_An_Hon\", 24: \"Lam_Giau_Voi_Ma\",\n",
    "    25: \"Lat_Mat_1\", 26: \"Lo_Mat\", 27: \"Ma_Da\", 28: \"Mat_Biec\",\n",
    "    29: \"Nhung_Nu_Hon_Ruc_Ro\", 30: \"Oan_Linh__Phan_1\", 31: \"Ong_Ngoai_Tuoi_30\",\n",
    "    32: \"Phap_Su_Tap_Su\", 33: \"Quy_Co_Thua_Ke\", 34: \"Ra_Mat_Gia_Tien\",\n",
    "    35: \"Sieu_Lua_Gap_Sieu_Lay\", 36: \"Sieu_Quay\", 37: \"Sieu_Tro_Ly\",\n",
    "    38: \"Taxi_Em_Ten_Gi\", 39: \"The_Call\", 40: \"Thien_Menh_Anh_Hung\",\n",
    "    41: \"Tieu_Thu_Va_Ba_Dau_Gau\", 42: \"Tren_Ban_Nhau_Duoi_Ban_Muu\"\n",
    "}\n",
    "class_to_idx = {name: idx for idx, name in classes.items()}\n",
    "idx_to_class = {idx: name for name, idx in class_to_idx.items()}\n",
    "\n",
    "# ==== Duy·ªát t·∫≠p test v√† l·∫•y ·∫£nh t·ª´ m·ªói th∆∞ m·ª•c ====\n",
    "y_true = []\n",
    "y_pred = []\n",
    "all_images = []\n",
    "for class_name in os.listdir(test_path):\n",
    "    class_dir = os.path.join(test_path, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "    # L·∫•y danh s√°ch ·∫£nh trong th∆∞ m·ª•c n√†y\n",
    "    image_files = [\n",
    "        os.path.join(class_dir, f)\n",
    "        for f in os.listdir(class_dir)\n",
    "        if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "    ]\n",
    "    # L·∫•y ng·∫´u nhi√™n n ·∫£nh t·ª´ folder (ho·∫∑c √≠t h∆°n n·∫øu kh√¥ng ƒë·ªß)\n",
    "    selected_images = random.sample(image_files, min(n_per_class, len(image_files)))\n",
    "    all_images.extend(selected_images)\n",
    "\n",
    "# ==== D·ª± ƒëo√°n ====\n",
    "for img_path in tqdm(all_images, desc=\"Testing with FAISS\"):\n",
    "    try:\n",
    "        folder_name = os.path.basename(os.path.dirname(img_path))\n",
    "        if folder_name not in class_to_idx:\n",
    "            print(f\"‚ùå Folder kh√¥ng h·ª£p l·ªá: {folder_name}\")\n",
    "            continue\n",
    "        img = image.load_img(img_path, target_size=(image_size, image_size))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        # Tr√≠ch ƒë·∫∑c tr∆∞ng v·ªõi m√¥ h√¨nh\n",
    "        feature = model.predict(x, verbose=0)\n",
    "        \n",
    "        # ƒê·∫£m b·∫£o ƒë·∫∑c tr∆∞ng c√≥ ƒë·ªãnh d·∫°ng ph√π h·ª£p\n",
    "        feature = feature.astype(np.float32)\n",
    "        \n",
    "        # T√¨m ki·∫øm k=1 ƒëi·ªÉm g·∫ßn nh·∫•t trong FAISS index\n",
    "        D, I = index.search(feature, 1)\n",
    "        \n",
    "        # L·∫•y nh√£n d·ª± ƒëo√°n t·ª´ FAISS\n",
    "        pred_label_data = index_labels[I[0][0]]\n",
    "        if isinstance(pred_label_data, (np.ndarray, list)) and len(pred_label_data) > 1:\n",
    "            pred_label = int(np.argmax(pred_label_data)) + 1\n",
    "        else:\n",
    "            pred_label = int(pred_label_data)\n",
    "\n",
    "        y_true.append(class_to_idx[folder_name])\n",
    "        y_pred.append(pred_label)\n",
    "    except Exception as e:\n",
    "        print(f\"L·ªói ·∫£nh {img_path}: {e}\")\n",
    "        print(f\"  H√¨nh d·∫°ng ƒë·∫∑c tr∆∞ng: {feature.shape}, Ki·ªÉu d·ªØ li·ªáu: {feature.dtype}\")\n",
    "\n",
    "# ==== ƒê√°nh gi√° ====\n",
    "if len(y_true) == 0:\n",
    "    print(\"‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ƒë√°nh gi√°!\")\n",
    "else:\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    print(f\"\\n‚úÖ Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"‚úÖ ƒê√∫ng: {np.sum(y_true == y_pred)} / ‚ùå Sai: {np.sum(y_true != y_pred)}\")\n",
    "    \n",
    "    # ==== Confusion Matrix ====\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    class_labels = [classes[i] for i in sorted(classes.keys())]\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "    fig, ax = plt.subplots(figsize=(16, 16))\n",
    "    disp.plot(xticks_rotation=90, cmap='Blues', ax=ax, colorbar=False)\n",
    "    plt.title(\"Confusion Matrix (FAISS)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(confusion_output_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"\\nüñºÔ∏è Confusion matrix ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o '{confusion_output_path}'\")\n",
    "    \n",
    "    # ==== Classification Report ====\n",
    "    print(\"\\nüìÑ Classification Report:\")\n",
    "    report = classification_report(\n",
    "        y_true, y_pred, target_names=class_labels,\n",
    "        digits=2, output_dict=True\n",
    "    )\n",
    "    # Chuy·ªÉn b√°o c√°o ph√¢n lo·∫°i th√†nh DataFrame\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    if \"accuracy\" not in report_df.columns:\n",
    "        report_df[\"accuracy\"] = accuracy\n",
    "    print(report_df[[\"precision\", \"recall\", \"f1-score\", \"accuracy\"]])\n",
    "    \n",
    "    # Hi·ªÉn th·ªã c√°c tham s·ªë chung cho to√†n b·ªô ch∆∞∆°ng tr√¨nh\n",
    "    avg_precision = np.mean(report_df['precision'])\n",
    "    avg_recall = np.mean(report_df['recall'])\n",
    "    avg_f1 = np.mean(report_df['f1-score'])\n",
    "    print(\"\\nüìù C√°c tham s·ªë ƒë√°nh gi√° chung:\")\n",
    "    print(f\"  - Precision: {avg_precision:.2f}\")\n",
    "    print(f\"  - Recall: {avg_recall:.2f}\")\n",
    "    print(f\"  - F1-score: {avg_f1:.2f}\")\n",
    "    print(f\"  - Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # L∆∞u b√°o c√°o chi ti·∫øt v√†o t·ªáp CSV\n",
    "    report_df.to_csv(csv_output_path, index=True)\n",
    "    print(f\"\\nüìä B√°o c√°o ph√¢n lo·∫°i ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o '{csv_output_path}'\")\n",
    "    \n",
    "    # L∆∞u c√°c tham s·ªë ƒë√°nh gi√° chung v√†o t·ªáp CSV\n",
    "    evaluation_metrics = {\n",
    "        'precision': avg_precision,\n",
    "        'recall': avg_recall,\n",
    "        'f1-score': avg_f1,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "    evaluation_df = pd.DataFrame([evaluation_metrics])\n",
    "    evaluation_df.to_csv('evaluation_metrics_faiss.csv', index=False)\n",
    "    print(f\"\\nüìä C√°c tham s·ªë ƒë√°nh gi√° chung ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'evaluation_metrics_faiss.csv'\")\n",
    "    \n",
    "    # L∆∞u c·∫£ b√°o c√°o ph√¢n lo·∫°i v√† c√°c tham s·ªë chung v√†o m·ªôt t·ªáp CSV\n",
    "    final_df = report_df.copy()\n",
    "    final_df['average_precision'] = avg_precision\n",
    "    final_df['average_recall'] = avg_recall\n",
    "    final_df['average_f1-score'] = avg_f1\n",
    "    final_df['average_accuracy'] = accuracy\n",
    "    final_df.to_csv('final_classification_report_faiss.csv', index=True)\n",
    "    print(f\"\\nüìä B√°o c√°o ph√¢n lo·∫°i cu·ªëi c√πng ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'final_classification_report_faiss.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 + FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T14:10:48.210331Z",
     "iopub.status.busy": "2025-05-10T14:10:48.209711Z",
     "iopub.status.idle": "2025-05-10T14:11:23.829520Z",
     "shell.execute_reply": "2025-05-10T14:11:23.828791Z",
     "shell.execute_reply.started": "2025-05-10T14:10:48.210299Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 312/312 [00:35<00:00,  8.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# S·ªë batch\n",
    "num_batches = tf.data.experimental.cardinality(train_df).numpy()\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    base_model_vgg16 = VGG16(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        pooling='avg',\n",
    "        input_shape=(image_size, image_size, 3)\n",
    "    )\n",
    "\n",
    "# N∆°i l∆∞u ƒë·∫∑c tr∆∞ng v√† nh√£n\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "for images, labels in tqdm(train_df, total=num_batches, desc=\"Extracting features\"):\n",
    "    images_pp = preprocess_input(images)\n",
    "    features_batch = base_model_vgg16(images_pp, training=False)\n",
    "    all_features.append(features_batch.numpy())\n",
    "    all_labels.append(labels.numpy())\n",
    "\n",
    "# N·ªëi ƒë·∫∑c tr∆∞ng v√† nh√£n\n",
    "features_array = np.concatenate(all_features, axis=0)\n",
    "labels_array = np.concatenate(all_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T14:11:44.817248Z",
     "iopub.status.busy": "2025-05-10T14:11:44.816971Z",
     "iopub.status.idle": "2025-05-10T14:11:44.957141Z",
     "shell.execute_reply": "2025-05-10T14:11:44.956533Z",
     "shell.execute_reply.started": "2025-05-10T14:11:44.817227Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ th√™m 39833 vector v√†o FAISS index.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "# K√≠ch th∆∞·ªõc vector ƒë·∫∑c tr∆∞ng\n",
    "d = features_array.shape[1]  \n",
    "\n",
    "# Kh·ªüi t·∫°o index\n",
    "index = faiss.IndexFlatL2(d)  # D√πng kho·∫£ng c√°ch Euclidean\n",
    "\n",
    "# Th√™m c√°c vector v√†o index\n",
    "index.add(features_array.astype('float32'))\n",
    "print(\"ƒê√£ th√™m\", index.ntotal, \"vector v√†o FAISS index.\")\n",
    "\n",
    "faiss.write_index(index, \"faiss_features.index\")\n",
    "np.save(\"faiss_labels.npy\", labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ƒê·ªçc l·∫°i FAISS index v√† nh√£n\n",
    "index = faiss.read_index(\"faiss_features.index\")\n",
    "labels_array = np.load(\"faiss_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T14:11:56.564589Z",
     "iopub.status.busy": "2025-05-10T14:11:56.563841Z",
     "iopub.status.idle": "2025-05-10T14:14:38.440392Z",
     "shell.execute_reply": "2025-05-10T14:14:38.439606Z",
     "shell.execute_reply.started": "2025-05-10T14:11:56.564563Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# C√†i ƒë·∫∑t c√°c tham s·ªë\n",
    "image_size = 128\n",
    "test_path = \"/kaggle/input/frames-film-vietnam-dataset/Frame_Test\"\n",
    "index_path = \"faiss_features.index\" \n",
    "label_path = \"faiss_labels.npy\"      \n",
    "confusion_output_path = \"confusion_matrix_faiss.jpg\"\n",
    "csv_output_path = \"classification_report_faiss.csv\"\n",
    "n_per_class = 50\n",
    "\n",
    "# ==== Load m√¥ h√¨nh v√† FAISS index ====\n",
    "model = VGG16(include_top=False, weights='imagenet', pooling='avg', input_shape=(image_size, image_size, 3))\n",
    "\n",
    "# Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n FAISS index v√† labels\n",
    "if not os.path.exists(index_path):\n",
    "    print(f\"‚ùå Kh√¥ng t√¨m th·∫•y FAISS index t·∫°i: {index_path}\")\n",
    "if not os.path.exists(label_path):\n",
    "    print(f\"‚ùå Kh√¥ng t√¨m th·∫•y nh√£n t·∫°i: {label_path}\")\n",
    "\n",
    "# Load FAISS index v√† labels\n",
    "try:\n",
    "    # Load index tr·ª±c ti·∫øp cho CPU\n",
    "    index = faiss.read_index(index_path)\n",
    "\n",
    "    # Load labels\n",
    "    index_labels = np.load(label_path)\n",
    "\n",
    "    print(f\"‚úÖ FAISS index ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!\")\n",
    "    print(f\"   - S·ªë l∆∞·ª£ng vectors: {index.ntotal}\")\n",
    "    print(f\"   - K√≠ch th∆∞·ªõc vector: {index.d}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå L·ªói khi t·∫£i FAISS index: {e}\")\n",
    "\n",
    "# ==== Mapping classes ====\n",
    "classes = {\n",
    "    1: \"21_Ngay_Yeu_Em\", 2: \"An_Tet_Ben_Con\", 3: \"Bay_Ngot_Ngao\", 4: \"Benh_Vien_Ma\",\n",
    "    5: \"Bi_Mat_Lai_Bi_Mat\", 6: \"Bi_Mat_Trong_Suong_Mu\", 7: \"Bo_Tu_Oan_Gia\", 8: \"Cho_Em_Den_Ngay_Mai\",\n",
    "    9: \"Chu_Tich_Giao_Hang\", 10: \"Chuyen_Tet\", 11: \"Co_Ba_Sai_Gon\", 12: \"Dao_Pho_Va_Piano\",\n",
    "    13: \"Dat_Phuong_Nam\", 14: \"Dia_Dao\", 15: \"Dinh_Menh_Thien_Y\", 16: \"Em_Chua_18\",\n",
    "    17: \"Em_La_Cua_Em\", 18: \"Gai_Gia_Lam_Chieu_3\", 19: \"Gia_Ngheo_Gap_Phat\", 20: \"Hem_Cut\",\n",
    "    21: \"Hoan_Doi\", 22: \"Ke_An_Danh\", 23: \"Ke_An_Hon\", 24: \"Lam_Giau_Voi_Ma\",\n",
    "    25: \"Lat_Mat_1\", 26: \"Lo_Mat\", 27: \"Ma_Da\", 28: \"Mat_Biec\",\n",
    "    29: \"Nhung_Nu_Hon_Ruc_Ro\", 30: \"Oan_Linh__Phan_1\", 31: \"Ong_Ngoai_Tuoi_30\",\n",
    "    32: \"Phap_Su_Tap_Su\", 33: \"Quy_Co_Thua_Ke\", 34: \"Ra_Mat_Gia_Tien\",\n",
    "    35: \"Sieu_Lua_Gap_Sieu_Lay\", 36: \"Sieu_Quay\", 37: \"Sieu_Tro_Ly\",\n",
    "    38: \"Taxi_Em_Ten_Gi\", 39: \"The_Call\", 40: \"Thien_Menh_Anh_Hung\",\n",
    "    41: \"Tieu_Thu_Va_Ba_Dau_Gau\", 42: \"Tren_Ban_Nhau_Duoi_Ban_Muu\"\n",
    "}\n",
    "class_to_idx = {name: idx for idx, name in classes.items()}\n",
    "idx_to_class = {idx: name for name, idx in class_to_idx.items()}\n",
    "\n",
    "# ==== Duy·ªát t·∫≠p test v√† l·∫•y ·∫£nh t·ª´ m·ªói th∆∞ m·ª•c ====\n",
    "y_true = []\n",
    "y_pred = []\n",
    "all_images = []\n",
    "for class_name in os.listdir(test_path):\n",
    "    class_dir = os.path.join(test_path, class_name)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        continue\n",
    "    # L·∫•y danh s√°ch ·∫£nh trong th∆∞ m·ª•c n√†y\n",
    "    image_files = [\n",
    "        os.path.join(class_dir, f)\n",
    "        for f in os.listdir(class_dir)\n",
    "        if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "    ]\n",
    "    # L·∫•y ng·∫´u nhi√™n n ·∫£nh t·ª´ folder (ho·∫∑c √≠t h∆°n n·∫øu kh√¥ng ƒë·ªß)\n",
    "    selected_images = random.sample(image_files, min(n_per_class, len(image_files)))\n",
    "    all_images.extend(selected_images)\n",
    "\n",
    "# ==== D·ª± ƒëo√°n ====\n",
    "for img_path in tqdm(all_images, desc=\"Testing with FAISS\"):\n",
    "    try:\n",
    "        folder_name = os.path.basename(os.path.dirname(img_path))\n",
    "        if folder_name not in class_to_idx:\n",
    "            print(f\"‚ùå Folder kh√¥ng h·ª£p l·ªá: {folder_name}\")\n",
    "            continue\n",
    "        img = image.load_img(img_path, target_size=(image_size, image_size))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        # Tr√≠ch ƒë·∫∑c tr∆∞ng v·ªõi m√¥ h√¨nh\n",
    "        feature = model.predict(x, verbose=0)\n",
    "        \n",
    "        # ƒê·∫£m b·∫£o ƒë·∫∑c tr∆∞ng c√≥ ƒë·ªãnh d·∫°ng ph√π h·ª£p\n",
    "        feature = feature.astype(np.float32)\n",
    "        \n",
    "        # T√¨m ki·∫øm k=1 ƒëi·ªÉm g·∫ßn nh·∫•t trong FAISS index\n",
    "        D, I = index.search(feature, 1)\n",
    "        \n",
    "        # L·∫•y nh√£n d·ª± ƒëo√°n t·ª´ FAISS\n",
    "        pred_label_data = index_labels[I[0][0]]\n",
    "        if isinstance(pred_label_data, (np.ndarray, list)) and len(pred_label_data) > 1:\n",
    "            pred_label = int(np.argmax(pred_label_data)) + 1\n",
    "        else:\n",
    "            pred_label = int(pred_label_data)\n",
    "\n",
    "        y_true.append(class_to_idx[folder_name])\n",
    "        y_pred.append(pred_label)\n",
    "    except Exception as e:\n",
    "        print(f\"L·ªói ·∫£nh {img_path}: {e}\")\n",
    "        print(f\"  H√¨nh d·∫°ng ƒë·∫∑c tr∆∞ng: {feature.shape}, Ki·ªÉu d·ªØ li·ªáu: {feature.dtype}\")\n",
    "\n",
    "# ==== ƒê√°nh gi√° ====\n",
    "if len(y_true) == 0:\n",
    "    print(\"‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ ƒë√°nh gi√°!\")\n",
    "else:\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    print(f\"\\n‚úÖ Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"‚úÖ ƒê√∫ng: {np.sum(y_true == y_pred)} / ‚ùå Sai: {np.sum(y_true != y_pred)}\")\n",
    "    \n",
    "    # ==== Confusion Matrix ====\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    class_labels = [classes[i] for i in sorted(classes.keys())]\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "    fig, ax = plt.subplots(figsize=(16, 16))\n",
    "    disp.plot(xticks_rotation=90, cmap='Blues', ax=ax, colorbar=False)\n",
    "    plt.title(\"Confusion Matrix (FAISS)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(confusion_output_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"\\nüñºÔ∏è Confusion matrix ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o '{confusion_output_path}'\")\n",
    "    \n",
    "    # ==== Classification Report ====\n",
    "    print(\"\\nüìÑ Classification Report:\")\n",
    "    report = classification_report(\n",
    "        y_true, y_pred, target_names=class_labels,\n",
    "        digits=2, output_dict=True\n",
    "    )\n",
    "    # Chuy·ªÉn b√°o c√°o ph√¢n lo·∫°i th√†nh DataFrame\n",
    "    report_df = pd.DataFrame(report).transpose()\n",
    "    if \"accuracy\" not in report_df.columns:\n",
    "        report_df[\"accuracy\"] = accuracy\n",
    "    print(report_df[[\"precision\", \"recall\", \"f1-score\", \"accuracy\"]])\n",
    "    \n",
    "    # Hi·ªÉn th·ªã c√°c tham s·ªë chung cho to√†n b·ªô ch∆∞∆°ng tr√¨nh\n",
    "    avg_precision = np.mean(report_df['precision'])\n",
    "    avg_recall = np.mean(report_df['recall'])\n",
    "    avg_f1 = np.mean(report_df['f1-score'])\n",
    "    print(\"\\nüìù C√°c tham s·ªë ƒë√°nh gi√° chung:\")\n",
    "    print(f\"  - Precision: {avg_precision:.2f}\")\n",
    "    print(f\"  - Recall: {avg_recall:.2f}\")\n",
    "    print(f\"  - F1-score: {avg_f1:.2f}\")\n",
    "    print(f\"  - Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # L∆∞u b√°o c√°o chi ti·∫øt v√†o t·ªáp CSV\n",
    "    report_df.to_csv(csv_output_path, index=True)\n",
    "    print(f\"\\nüìä B√°o c√°o ph√¢n lo·∫°i ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o '{csv_output_path}'\")\n",
    "    \n",
    "    # L∆∞u c√°c tham s·ªë ƒë√°nh gi√° chung v√†o t·ªáp CSV\n",
    "    evaluation_metrics = {\n",
    "        'precision': avg_precision,\n",
    "        'recall': avg_recall,\n",
    "        'f1-score': avg_f1,\n",
    "        'accuracy': accuracy\n",
    "    }\n",
    "    evaluation_df = pd.DataFrame([evaluation_metrics])\n",
    "    evaluation_df.to_csv('evaluation_metrics_faiss.csv', index=False)\n",
    "    print(f\"\\nüìä C√°c tham s·ªë ƒë√°nh gi√° chung ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'evaluation_metrics_faiss.csv'\")\n",
    "    \n",
    "    # L∆∞u c·∫£ b√°o c√°o ph√¢n lo·∫°i v√† c√°c tham s·ªë chung v√†o m·ªôt t·ªáp CSV\n",
    "    final_df = report_df.copy()\n",
    "    final_df['average_precision'] = avg_precision\n",
    "    final_df['average_recall'] = avg_recall\n",
    "    final_df['average_f1-score'] = avg_f1\n",
    "    final_df['average_accuracy'] = accuracy\n",
    "    final_df.to_csv('final_classification_report_faiss.csv', index=True)\n",
    "    print(f\"\\nüìä B√°o c√°o ph√¢n lo·∫°i cu·ªëi c√πng ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'final_classification_report_faiss.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7379070,
     "sourceId": 11754070,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
