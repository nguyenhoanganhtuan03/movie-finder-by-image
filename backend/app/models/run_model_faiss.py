import os
import time
import numpy as np
import faiss
import cv2
from collections import Counter

from tensorflow.keras.applications import ResNet50, VGG16
# from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras.preprocessing import image

# ==== Cáº¥u hÃ¬nh ====
image_size = 128
base_dir = os.path.dirname(os.path.abspath(__file__))
index_path = os.path.join(base_dir, "features_faiss_more_data/vgg16/faiss_features.index")
label_path = os.path.join(base_dir, "features_faiss_more_data/vgg16/faiss_labels.npy")
similarity_threshold = 0.8

# ==== Load model ResNet50 ====
# model = ResNet50(include_top=False, weights='imagenet', pooling='avg', input_shape=(image_size, image_size, 3))
model = VGG16(include_top=False, weights='imagenet', pooling='avg', input_shape=(image_size, image_size, 3))

# ==== Load FAISS index vÃ  labels ====
if not os.path.exists(index_path) or not os.path.exists(label_path):
    print("âŒ KhÃ´ng tÃ¬m tháº¥y FAISS index hoáº·c labels.")
    exit()

index = faiss.read_index(index_path)
index_labels = np.load(label_path)

# ==== Danh sÃ¡ch phim (mapping) ====
# ThÃªm Linh MiÃªu Quá»· Nháº­p TrÃ ng, ÄÃ´i Máº¯t Ã‚m DÆ°Æ¡ng, Nghá» SiÃªu Dá»…, Táº¥m CÃ¡m Chuyá»‡n ChÆ°a Ká»ƒ
# Cháº¡y láº¡i Dataset
classes = {
    1: "21 NgÃ y yÃªu em", 2: "Ä‚n táº¿t bÃªn cá»“n", 3: "Báº«y ngá»t ngÃ o", 4: "Bá»‡nh viá»‡n ma",
    5: "BÃ­ máº­t láº¡i bá»‹ máº¥t", 6: "BÃ­ máº­t trong sÆ°Æ¡ng mÃ¹", 7: "Bá»™ tá»© oan gia", 8: "Chá» em Ä‘áº¿n ngÃ y mai",
    9: "Chá»§ tá»‹ch giao hÃ ng", 10: "Chuyá»‡n táº¿t", 11: "CÃ´ ba sÃ i gÃ²n", 12: "ÄÃ o, phá»Ÿ vÃ  piano",
    13: "Äáº¥t rá»«ng phÆ°Æ¡ng nam", 14: "Äá»‹a Ä‘áº¡o", 15: "Äá»‹nh má»‡nh thiÃªn y", 16: "Em chÆ°a 18",
    17: "Em lÃ  cá»§a em", 18: "GÃ¡i giÃ  láº¯m chiÃªu", 19: "Giáº£ nghÃ¨o gáº·p pháº­t", 20: "Háº»m cá»¥t",
    21: "HoÃ¡n Ä‘á»•i", 22: "Káº» áº©n danh", 23: "Káº» Äƒn há»“n", 24: "LÃ m giÃ u vá»›i ma",
    25: "Láº­t máº·t 1", 26: "Lá»™ máº·t", 27: "Ma da", 28: "Máº¯t biáº¿c",
    29: "Nhá»¯ng ná»¥ hÃ´n rá»±c rá»¡", 30: "OÃ¡n linh", 31: "Ã”ng ngoáº¡i tuá»•i 30", 32: "PhÃ¡p sÆ° táº­p sá»±",
    33: "QuÃ½ cÃ´ thá»«a káº¿", 34: "Ra máº¯t gia tiÃªn", 35: "SiÃªu lá»«a gáº·p siÃªu láº§y", 36: "4 nÄƒm 2 chÃ ng 1 tÃ¬nh yÃªu",
    37: "SiÃªu trá»£ lÃ½", 38: "Taxi em tÃªn gÃ¬", 39: "The Call", 40: "ThiÃªn má»‡nh anh hÃ¹ng",
    41: "Tiá»ƒu thÆ° vÃ  ba Ä‘áº§u gáº¥u", 42: "TrÃªn bÃ n nháº­u dÆ°á»›i bÃ n mÆ°u", 43: "KhÃ¡c"
}

# Chuáº©n hÃ³a L2 cho má»—i vector (Ä‘á»™ dÃ i = 1)
def l2_normalize(vectors):
    norms = np.linalg.norm(vectors, axis=1, keepdims=True)
    return vectors / (norms + 1e-10)  # thÃªm epsilon Ä‘á»ƒ trÃ¡nh chia cho 0

# ==== HÃ m dá»± Ä‘oÃ¡n ====
# HÃ m xá»­ lÃ½ áº£nh
def predict_film_from_image(img_path):
    img = image.load_img(img_path, target_size=(image_size, image_size))
    x = image.img_to_array(img)
    x = np.expand_dims(x, axis=0)
    x = preprocess_input(x)

    feature = model.predict(x, verbose=0)
    feature = l2_normalize(feature)
    feature = feature.astype(np.float32)
    D, I = index.search(feature, 1)

    euclidean_dist_squared = D[0][0]
    similarity_score = 1 - euclidean_dist_squared / 2  # Chuyá»ƒn Ä‘á»•i khoáº£ng cÃ¡ch thÃ nh cosine similarity

    # Náº¿u similarity dÆ°á»›i ngÆ°á»¡ng, gÃ¡n nhÃ£n "KhÃ¡c" (43)
    if similarity_score < similarity_threshold:
        pred_label = 43  # NhÃ£n "KhÃ¡c"
    else:
        # Láº¥y nhÃ£n dá»± Ä‘oÃ¡n tá»« FAISS
        pred_label_data = index_labels[I[0][0]]
        if isinstance(pred_label_data, (np.ndarray, list)) and len(pred_label_data) > 1:
            pred_label = int(np.argmax(pred_label_data)) + 1
        else:
            pred_label = int(pred_label_data)

    film_name = classes.get(pred_label, "KhÃ´ng xÃ¡c Ä‘á»‹nh")
    return film_name

# HÃ m xá»­ lÃ½ video
def predict_film_from_video(video_path):
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        return "âŒ KhÃ´ng má»Ÿ Ä‘Æ°á»£c video."

    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    if total_frames == 0:
        return "âŒ Video khÃ´ng cÃ³ frame nÃ o."

    # 5 frame
    frame_indices = [
        0,
        total_frames // 4,
        total_frames // 2,
        (3 * total_frames) // 4,
        total_frames - 1
    ]
    predictions = []

    for idx in frame_indices:
        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
        ret, frame = cap.read()
        if not ret:
            continue  # Bá» qua náº¿u khÃ´ng Ä‘á»c Ä‘Æ°á»£c frame

        frame = cv2.resize(frame, (image_size, image_size))
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        x = np.expand_dims(frame, axis=0)
        x = preprocess_input(x)

        feature = model.predict(x, verbose=0)
        feature = l2_normalize(feature)
        feature = feature.astype(np.float32)
        D, I = index.search(feature, 1)

        euclidean_dist_squared = D[0][0]
        similarity_score = 1 - euclidean_dist_squared / 2  # Chuyá»ƒn Ä‘á»•i khoáº£ng cÃ¡ch thÃ nh cosine similarity

        # Náº¿u similarity dÆ°á»›i ngÆ°á»¡ng, gÃ¡n nhÃ£n "KhÃ¡c" (43)
        if similarity_score < similarity_threshold:
            pred_label = 43
        else:
            # Láº¥y nhÃ£n dá»± Ä‘oÃ¡n tá»« FAISS
            pred_label_data = index_labels[I[0][0]]
            if isinstance(pred_label_data, (np.ndarray, list)) and len(pred_label_data) > 1:
                pred_label = int(np.argmax(pred_label_data)) + 1
            else:
                pred_label = int(pred_label_data)

        predictions.append(pred_label)

    cap.release()

    if not predictions:
        return "âŒ KhÃ´ng Ä‘á»c Ä‘Æ°á»£c frame há»£p lá»‡ nÃ o."

    most_common_id = Counter(predictions).most_common(1)[0][0]
    film_name = classes.get(most_common_id, "KhÃ´ng xÃ¡c Ä‘á»‹nh")
    return film_name


# HÃ m tá»± Ä‘á»™ng nháº­n biáº¿t loáº¡i file vÃ  xá»­ lÃ½
def predict_film_auto(input_path):
    try:
        start_time = time.time()
        ext = os.path.splitext(input_path)[-1].lower()

        if ext in ['.jpg', '.jpeg', '.png']:
            film_name = predict_film_from_image(input_path)
        elif ext in ['.mp4', '.avi', '.mov', '.mkv']:
            film_name = predict_film_from_video(input_path)
        else:
            return "âŒ Äá»‹nh dáº¡ng khÃ´ng há»— trá»£."

        end_time = time.time()
        print(f"â±ï¸ Thá»i gian xá»­ lÃ½: {end_time - start_time:.4f} giÃ¢y")
        return film_name

    except Exception as e:
        return f"âŒ Lá»—i khi xá»­ lÃ½: {e}"

# ==== Test ====
# input_path = os.path.join(base_dir, "img_test/4_2_1.jpg")
# predicted_film = predict_film_auto(input_path)
# print(f"ğŸ¬ Dá»± Ä‘oÃ¡n: {predicted_film}")
