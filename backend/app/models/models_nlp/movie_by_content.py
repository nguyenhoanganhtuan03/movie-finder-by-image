import os
import json
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
from collections import Counter

from langchain_community.llms import CTransformers
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# ========== C·∫•u h√¨nh ==========
VECTOR_PATH = "vector_db/vector_similarity.faiss"
METADATA_PATH = "vector_db/movie_metadata.json"
EMBEDDING_MODEL = "AITeamVN/Vietnamese_Embedding"
GGUF_MODEL_PATH = "models_llm/vinallama-7b-chat_q5_0.gguf"
similarity_threshold = 0.4
os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"

# ========== Load model nh√∫ng ==========
model = SentenceTransformer(EMBEDDING_MODEL)
model.max_seq_length = 2048

# ========== Chu·∫©n h√≥a vector ==========
def l2_normalize(vectors):
    norms = np.linalg.norm(vectors, axis=1, keepdims=True)
    return vectors / (norms + 1e-10)

# ========== Load FAISS & metadata ==========
if not os.path.exists(VECTOR_PATH) or not os.path.exists(METADATA_PATH):
    raise FileNotFoundError("‚ùå FAISS index ho·∫∑c metadata ch∆∞a t·ªìn t·∫°i.")

index = faiss.read_index(VECTOR_PATH)
with open(METADATA_PATH, "r", encoding="utf-8") as f:
    metadata = json.load(f)

# ========== Load m√¥ h√¨nh PhoGPT ==========
if not os.path.exists(GGUF_MODEL_PATH):
    raise FileNotFoundError("‚ùå PhoGPT model ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t.")

llm = CTransformers(
    model=GGUF_MODEL_PATH,
    model_type="llama",
    config={"max_new_tokens": 512, "temperature": 0.01}
)

# ========== T·∫°o prompt ph√¢n t√≠ch ==========
prompt_template = PromptTemplate(
    input_variables=["query"],
    template="""
        B·∫°n l√† tr·ª£ l√Ω AI. H√£y ph√¢n t√≠ch m√¥ t·∫£ sau v√† t√°ch n√≥ th√†nh c√°c ph·∫ßn c·ª• th·ªÉ nh∆∞:
        - Di·ªÖn vi√™n:
        - Th·ªÉ lo·∫°i:
        - ƒê·∫°o di·ªÖn:
        - N·ªôi dung:
        - NƒÉm ph√°t h√†nh (n·∫øu c√≥):
        
        N·∫øu kh√¥ng c√≥ ph·∫ßn n√†o, h√£y ƒë·ªÉ tr·ªëng ph·∫ßn ƒë√≥.
        
        M√¥ t·∫£: "{query}"
        ---
        """
    )

chain = LLMChain(prompt=prompt_template, llm=llm)

# ========== Nh·∫≠n truy v·∫•n ng∆∞·ªùi d√πng ==========
query = input("üîç Nh·∫≠p n·ªôi dung m√¥ t·∫£ phim: ").strip()
structured_info = chain.run(query)

print("\nüìã Truy v·∫•n ƒë√£ ph√¢n t√≠ch:\n", structured_info)

# ========== Chuy·ªÉn truy v·∫•n ph√¢n t√≠ch th√†nh vƒÉn b·∫£n chu·∫©n ƒë·ªÉ nh√∫ng ==========
def convert_to_clean_text(info_str):
    lines = info_str.strip().splitlines()
    final_text = ""
    for line in lines:
        if ":" in line:
            key, value = line.split(":", 1)
            final_text += f"{key.strip().capitalize()}: {value.strip()}. "
    return final_text.strip()

processed_query = convert_to_clean_text(structured_info)
query_vector = l2_normalize(model.encode([processed_query]).astype("float32"))
D, I = index.search(query_vector, k=5)

# ========== T√≠nh ƒëi·ªÉm t∆∞∆°ng ƒë·ªìng ==========
euclidean_dist_squared = D[0][0]
similarity_score = 1 - euclidean_dist_squared / 2

if similarity_score < similarity_threshold:
    print("Threshold:", similarity_score)
    print(f"‚ùå Kh√¥ng t√¨m th·∫•y phim n√†o ph√π h·ª£p v·ªõi truy v·∫•n '{query}'.")
    exit()

# ========== X·ª≠ l√Ω k·∫øt qu·∫£ ==========
names = [metadata[idx]["movie_name"] for idx in I[0]]
counter = Counter(names)
most_common = counter.most_common(1)[0]

if most_common[1] >= (len(names) / 2):
    chosen_movie = most_common[0]
else:
    chosen_movie = names[0]

print("Threshold:", similarity_score)
print(f"üé¨ Phim ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t: {chosen_movie}")
