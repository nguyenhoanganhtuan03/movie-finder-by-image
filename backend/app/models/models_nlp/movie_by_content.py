import os
import numpy as np
import faiss
import csv
from sentence_transformers import SentenceTransformer
from pyvi.ViTokenizer import tokenize

# ========== C·∫•u h√¨nh ==========
VECTOR_DIR = "vector_db"
INDEX_PATH = os.path.join(VECTOR_DIR, "index_movie.faiss")
PROMPT_MAPPING_PATH = os.path.join(VECTOR_DIR, "prompt_mapping.csv")
SIMILARITY_THRESHOLD = 0.3
EMBEDDING_MODEL = "AITeamVN/Vietnamese_Embedding"
# EMBEDDING_MODEL = "VoVanPhuc/sup-SimCSE-VietNamese-phobert-base"
METADATA_PATH = os.path.join(VECTOR_DIR, "metadata.csv")

# ========== Load m√¥ h√¨nh v√† FAISS ==========
model = SentenceTransformer(EMBEDDING_MODEL)
model.max_seq_length = 2048
index = faiss.read_index(INDEX_PATH)

# ========== H√†m ti·ªán √≠ch ==========
def l2_normalize(vectors):
    norms = np.linalg.norm(vectors, axis=1, keepdims=True)
    return vectors / (norms + 1e-10)

# def embed_text(text):
#     text = text.strip().lower()
#     tokenized = tokenize(text)
#     embedding = model.encode([tokenized], convert_to_numpy=True)
#     return l2_normalize(embedding)

def embed_text(text):
    text = text.strip().lower()
    return model.encode([text], convert_to_numpy=True)

# ========== Load metadata ==========
def load_metadata(path):
    metadata = {}
    if os.path.exists(path):
        with open(path, encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                idx = int(row['index'])
                name = row.get('name', f"Phim c√≥ ID {idx}")
                metadata[idx] = name
    return metadata

metadata_mapping = load_metadata(METADATA_PATH)

# ========== Load prompt mapping ==========
def load_prompt_mapping(path):
    mapping = {}
    if os.path.exists(path):
        with open(path, encoding='utf-8') as f:
            next(f)
            for line in f:
                line = line.strip()
                if not line:
                    continue
                parts = line.split(",", 1)
                if len(parts) != 2:
                    # print(f"B·ªè qua d√≤ng kh√¥ng h·ª£p l·ªá: {line}")
                    continue
                idx, prompt = parts
                try:
                    mapping[int(idx)] = prompt
                except ValueError:
                    # print(f"B·ªè qua d√≤ng c√≥ index kh√¥ng ph·∫£i s·ªë: {line}")
                    pass
    return mapping

prompt_mapping = load_prompt_mapping(PROMPT_MAPPING_PATH)

# ========== H√†m t√¨m phim t∆∞∆°ng t·ª± ==========
def find_similar_movies(query, top_k=5):
    query_vec = l2_normalize(embed_text(query).astype('float32'))
    distances, indices = index.search(query_vec, top_k)
    results = []
    for dist, idx in zip(distances[0], indices[0]):
        similarity = 1 - dist / 2
        if similarity >= SIMILARITY_THRESHOLD:
            movie_name = metadata_mapping.get(idx, f"Phim c√≥ ID {idx}")
            results.append((movie_name, similarity))
    return results

# ========== Main ==========
if __name__ == "__main__":
    while True:
        user_query = input("üîç Nh·∫≠p m√¥ t·∫£ phim b·∫°n mu·ªën t√¨m (ho·∫∑c g√µ 'quit' ƒë·ªÉ tho√°t): ").strip()
        if user_query.lower() == "quit":
            print("üëã K·∫øt th√∫c ch∆∞∆°ng tr√¨nh.")
            break

        matches = find_similar_movies(user_query, top_k=5)

        if not matches:
            print("‚ùå Kh√¥ng t√¨m th·∫•y phim ph√π h·ª£p v·ªõi m√¥ t·∫£ c·ªßa b·∫°n.")
        else:
            print("\nüé¨ C√°c phim g·∫ßn nh·∫•t v·ªõi m√¥ t·∫£ c·ªßa b·∫°n:")
            for i, (movie_prompt, score) in enumerate(matches, 1):
                print(f"{i}. {movie_prompt} (ƒë·ªô t∆∞∆°ng ƒë·ªìng: {score:.3f})")
