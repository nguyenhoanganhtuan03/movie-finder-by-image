import os
import requests
import csv
import numpy as np
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv
import faiss

# ==== Cáº¤U HÃŒNH ====
load_dotenv()
VECTOR_DIR = "vector_db"
INDEX_PATH = os.path.join(VECTOR_DIR, "index_movie.faiss")
PROMPT_MAPPING_PATH = os.path.join(VECTOR_DIR, "prompt_mapping.csv")
SIMILARITY_THRESHOLD = 0.3
EMBEDDING_MODEL = "AITeamVN/Vietnamese_Embedding"
METADATA_PATH = os.path.join(VECTOR_DIR, "metadata.csv")

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY_2")
GEMINI_API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent"

# ==== LOAD MODEL EMBEDDING vÃ  FAISS ====
model = SentenceTransformer(EMBEDDING_MODEL)
model.max_seq_length = 2048
index = faiss.read_index(INDEX_PATH)

# ========== HÃ€M TIá»†N ÃCH ==========
def l2_normalize(vectors):
    norms = np.linalg.norm(vectors, axis=1, keepdims=True)
    return vectors / (norms + 1e-10)

def embed_text(text):
    text = text.strip().lower()
    return model.encode([text], convert_to_numpy=True)

def load_metadata(path):
    metadata = {}
    if os.path.exists(path):
        with open(path, encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                idx = int(row['index'])
                name = row.get('name', f"Phim cÃ³ ID {idx}")
                metadata[idx] = name
    return metadata

metadata_mapping = load_metadata(METADATA_PATH)

def load_prompt_mapping(path):
    mapping = {}
    if os.path.exists(path):
        with open(path, encoding='utf-8') as f:
            next(f)
            for line in f:
                line = line.strip()
                if not line:
                    continue
                parts = line.split(",", 1)
                if len(parts) != 2:
                    # print(f"Bá» qua dÃ²ng khÃ´ng há»£p lá»‡: {line}")
                    continue
                idx, prompt = parts
                try:
                    mapping[int(idx)] = prompt
                except ValueError:
                    # print(f"Bá» qua dÃ²ng cÃ³ index khÃ´ng pháº£i sá»‘: {line}")
                    pass
    return mapping

prompt_mapping = load_prompt_mapping(PROMPT_MAPPING_PATH)

# ========== HÃ m tÃ¬m phim tÆ°Æ¡ng tá»± ==========
def find_similar_movies(query, top_k=5):
    query_vec = l2_normalize(embed_text(query).astype('float32'))
    distances, indices = index.search(query_vec, top_k)
    results = []
    for dist, idx in zip(distances[0], indices[0]):
        similarity = 1 - dist / 2
        if similarity >= SIMILARITY_THRESHOLD:
            movie_name = metadata_mapping.get(idx, f"Phim cÃ³ ID {idx}")
            results.append((movie_name, similarity))
    return results

# ========== HÃ€M Gá»ŒI GEMINI API ==========
def call_gemini_api(prompt, api_key=GEMINI_API_KEY):
    """
    Gá»i Gemini API Ä‘á»ƒ táº¡o cÃ¢u tráº£ lá»i
    """
    headers = {
        "Content-Type": "application/json"
    }

    data = {
        "contents": [
            {
                "parts": [
                    {"text": prompt}
                ]
            }
        ],
        "generationConfig": {
            "temperature": 0.01,
            "topK": 40,
            "topP": 0.95,
            "maxOutputTokens": 1024,
        }
    }

    try:
        response = requests.post(
            f"{GEMINI_API_URL}?key={api_key}",
            headers=headers,
            json=data,
            timeout=30
        )

        if response.status_code == 200:
            result = response.json()
            if "candidates" in result and len(result["candidates"]) > 0:
                content = result["candidates"][0]["content"]["parts"][0]["text"]
                return content.strip()
            else:
                return "âŒ KhÃ´ng nháº­n Ä‘Æ°á»£c pháº£n há»“i tá»« Gemini API."
        else:
            return f"âŒ Lá»—i API Gemini: {response.status_code} - {response.text}"

    except requests.exceptions.Timeout:
        return "âŒ Timeout khi gá»i Gemini API."
    except requests.exceptions.RequestException as e:
        return f"âŒ Lá»—i káº¿t ná»‘i: {str(e)}"
    except Exception as e:
        return f"âŒ Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {str(e)}"


# ========== PHÃ‚N TÃCH KEYWORD VÃ€ Táº O PROMPT ==========
def create_keyword_analysis_prompt(user_query):
    """
    Táº¡o prompt Ä‘á»ƒ Gemini phÃ¢n tÃ­ch keyword vÃ  trÃ­ch xuáº¥t thÃ´ng tin phim
    """
    prompt = f"""Báº¡n lÃ  má»™t chuyÃªn gia phÃ¢n tÃ­ch thÃ´ng tin phim áº£nh. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ :

1. PHÃ‚N TÃCH cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng Ä‘á»ƒ tÃ¬m tÃªn phim
2. TÃŒM KIáº¾M thÃ´ng tin phim tá»« dá»¯ liá»‡u Ä‘Æ°á»£c cung cáº¥p
3. TRÃCH XUáº¤T cÃ¡c thÃ´ng tin chÃ­nh cá»§a phim
4. TRáº¢ Vá»€ káº¿t quáº£ theo Ä‘á»‹nh dáº¡ng yÃªu cáº§u

CÃ‚U Há»I NGÆ¯á»œI DÃ™NG: "{user_query}"

NHIá»†M Vá»¤:
- Tá»« cÃ¢u há»i, hÃ£y xÃ¡c Ä‘á»‹nh cÃ¡c keywords chÃ­nh trong cÃ¢u há»i
- TrÃ­ch xuáº¥t cÃ¡c thÃ´ng tin: thá»ƒ loáº¡i, thá»i lÆ°á»£ng, Ä‘áº¡o diá»…n, diá»…n viÃªn, nÄƒm ra máº¯t, ná»™i dung

YÃŠU Cáº¦U Äá»ŠNH Dáº NG TRáº¢ Lá»œI:
Tráº£ lá»i chÃ­nh xÃ¡c theo máº«u sau (thay tháº¿ cÃ¡c pháº§n trong ngoáº·c nhá»n):

"Má»™t bá»™ phim thá»ƒ loáº¡i {{genre}}, kÃ©o dÃ i {{duration}} phÃºt, Ä‘Æ°á»£c Ä‘áº¡o diá»…n bá»Ÿi {{director}}, vá»›i sá»± tham gia cá»§a {{actor}}, ra máº¯t vÃ o nÄƒm {{year}}. Ná»™i dung phim: {{description}}"

LÆ°U Ã:
- Náº¿u khÃ´ng tÃ¬m tháº¥y thÃ´ng tin nÃ o, hÃ£y bá» qua thÃ´ng tin Ä‘Ã³ trong cÃ¢u máº«u.
- Chá»‰ sá»­ dá»¥ng thÃ´ng tin cÃ³ trong cÃ¢u há»i ngÆ°á»i dÃ¹ng.
VÃ­ dá»¥:
    - CÃ‚U Há»I NGÆ¯á»œI DÃ™NG: phim kinh dá»‹ cÃ³ Viá»‡t HÆ°Æ¡ng Ä‘Ã³ng
    - TRáº¢ Lá»œI: Má»™t bá»™ phim thá»ƒ loáº¡i kinh dá»‹, vá»›i sá»± tham gia cá»§a Viá»‡t HÆ°Æ¡ng.

TRáº¢ Lá»œI:"""

    return call_gemini_api(prompt)

# ========== HÃ€M PHÃ‚N TÃCH CÃ‚U Há»I ==========
def search_movies_by_user_query(user_query, top_k=5):
    # 1. Sinh prompt truy váº¥n tá»« Gemini
    search_prompt = create_keyword_analysis_prompt(user_query)

    # 2. Embed vÃ  tÃ¬m trong FAISS
    query_vec = l2_normalize(embed_text(search_prompt).astype('float32'))
    distances, indices = index.search(query_vec, top_k)

    results = []
    for dist, idx in zip(distances[0], indices[0]):
        similarity = 1 - dist / 2
        if similarity >= SIMILARITY_THRESHOLD:
            movie_name = metadata_mapping.get(idx, f"Phim cÃ³ ID {idx}")
            results.append((movie_name, similarity))

    return search_prompt, results

# ========== MAIN ==========
while True:
    user_input = input("Nháº­p cÃ¢u há»i cá»§a báº¡n (hoáº·c 'quit' Ä‘á»ƒ thoÃ¡t): ").strip()
    if user_input.lower() == "quit":
        print("ğŸ‘‹ ThoÃ¡t chÆ°Æ¡ng trÃ¬nh.")
        break

    prompt, movies = search_movies_by_user_query(user_input)

    print("\nğŸ§  Prompt dÃ¹ng Ä‘á»ƒ truy váº¥n:", prompt)
    if movies:
        print("ğŸ¬ Káº¿t quáº£ tÃ¬m Ä‘Æ°á»£c:")
        for name, score in movies:
            print(f"- {name} (Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng: {score:.2f})")
    else:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y phim phÃ¹ há»£p.\n")
