import os
import requests
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv

from langchain_community.vectorstores import FAISS
from langchain.embeddings.base import Embeddings

# ==== C·∫§U H√åNH ====
load_dotenv()
VECTOR_DIR = "vector_db"
MOVIE_VECTOR_DB = os.path.join(VECTOR_DIR, "movie_vector_db")
EMBEDDING_MODEL = "AITeamVN/Vietnamese_Embedding"

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GEMINI_API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent"

# ==== LOAD MODEL EMBEDDING ====
model = SentenceTransformer(EMBEDDING_MODEL)
model.max_seq_length = 2048


# ========== WRAPPER EMBEDDING CHO LANGCHAIN ==========
class SentenceTransformerEmbeddingWrapper(Embeddings):
    def __init__(self, model):
        self.model = model

    def embed_documents(self, texts):
        embeddings = self.model.encode(texts, convert_to_numpy=True)
        return embeddings.tolist()

    def embed_query(self, text):
        embedding = self.model.encode([text], convert_to_numpy=True)[0]
        return embedding.tolist()


embedding_wrapper = SentenceTransformerEmbeddingWrapper(model)


# ========== H√ÄM G·ªåI GEMINI API ==========
def call_gemini_api(prompt, api_key):
    """
    G·ªçi Gemini API ƒë·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi
    """
    headers = {
        "Content-Type": "application/json"
    }

    data = {
        "contents": [
            {
                "parts": [
                    {"text": prompt}
                ]
            }
        ],
        "generationConfig": {
            "temperature": 0.7,
            "topK": 40,
            "topP": 0.95,
            "maxOutputTokens": 1024,
        }
    }

    try:
        response = requests.post(
            f"{GEMINI_API_URL}?key={api_key}",
            headers=headers,
            json=data,
            timeout=30
        )

        if response.status_code == 200:
            result = response.json()
            if "candidates" in result and len(result["candidates"]) > 0:
                content = result["candidates"][0]["content"]["parts"][0]["text"]
                return content.strip()
            else:
                return "‚ùå Kh√¥ng nh·∫≠n ƒë∆∞·ª£c ph·∫£n h·ªìi t·ª´ Gemini API."
        else:
            return f"‚ùå L·ªói API Gemini: {response.status_code} - {response.text}"

    except requests.exceptions.Timeout:
        return "‚ùå Timeout khi g·ªçi Gemini API."
    except requests.exceptions.RequestException as e:
        return f"‚ùå L·ªói k·∫øt n·ªëi: {str(e)}"
    except Exception as e:
        return f"‚ùå L·ªói kh√¥ng x√°c ƒë·ªãnh: {str(e)}"


# ========== T·∫†O PROMPT TEMPLATE ==========
def create_qa_prompt(context, question, chat_history=None, previous_contexts=None):
    """
    T·∫°o prompt v·ªõi l·ªãch s·ª≠ chat v√† context t·ª´ c√°c t√¨m ki·∫øm tr∆∞·ªõc
    """
    history_text = ""
    if chat_history:
        history_text = "\nL·ªäCH S·ª¨ CU·ªòC TR√í CHUY·ªÜN:\n"
        for i, (q, a) in enumerate(chat_history, 1):
            history_text += f"{i}. H·ªèi: {q}\n   Tr·∫£ l·ªùi: {a}\n"
        history_text += "\n"

    # Th√™m context t·ª´ c√°c t√¨m ki·∫øm tr∆∞·ªõc
    previous_context_text = ""
    if previous_contexts:
        previous_context_text = "\nTH√îNG TIN T·ª™ C√ÅC T√åM KI·∫æM TR∆Ø·ªöC:\n"
        for i, prev_context in enumerate(previous_contexts, 1):
            previous_context_text += f"Context {i}:\n{prev_context}\n\n"

    prompt = f"""B·∫°n l√† m·ªôt tr·ª£ l√Ω AI chuy√™n tr·∫£ l·ªùi c√¢u h·ªèi v·ªÅ phim ·∫£nh. S·ª≠ d·ª•ng th√¥ng tin sau ƒë√¢y ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch ch√≠nh x√°c v√† ng·∫Øn g·ªçn.

TH√îNG TIN THAM KH·∫¢O CHO C√ÇU H·ªéI HI·ªÜN T·∫†I:
{context}
{previous_context_text}{history_text}
C√ÇU H·ªéI HI·ªÜN T·∫†I: {question}

H∆Ø·ªöNG D·∫™N:
- ∆Øu ti√™n s·ª≠ d·ª•ng th√¥ng tin t·ª´ "TH√îNG TIN THAM KH·∫¢O CHO C√ÇU H·ªéI HI·ªÜN T·∫†I"
- C√≥ th·ªÉ tham kh·∫£o th√¥ng tin t·ª´ c√°c t√¨m ki·∫øm tr∆∞·ªõc v√† l·ªãch s·ª≠ chat ƒë·ªÉ hi·ªÉu ng·ªØ c·∫£nh t·ªët h∆°n
- Tr·∫£ l·ªùi ng·∫Øn g·ªçn, ch√≠nh x√°c
- N·∫øu c√¢u h·ªèi li√™n quan ƒë·∫øn c√¢u h·ªèi tr∆∞·ªõc, h√£y li√™n k·∫øt th√¥ng tin t·ª´ c√°c ngu·ªìn kh√°c nhau
- N·∫øu kh√¥ng t√¨m th·∫•y th√¥ng tin, n√≥i "T√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin v·ªÅ c√¢u h·ªèi n√†y."
- Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát

TR·∫¢ L·ªúI:"""

    return prompt


# ========== H·ªÜ TH·ªêNG QA CH√çNH ==========
class MovieQASystem:
    def __init__(self, vector_db, api_key, max_history=5, max_contexts=2):
        self.db = vector_db
        self.api_key = api_key
        self.chat_history = []
        self.context_history = []
        self.max_history = max_history
        self.max_contexts = max_contexts

    def search_relevant_docs(self, question, k=3):
        """
        T√¨m ki·∫øm c√°c document li√™n quan ƒë·∫øn c√¢u h·ªèi
        """
        try:
            docs = self.db.similarity_search(question, k=k)
            return docs
        except Exception as e:
            print(f"‚ùå L·ªói khi t√¨m ki·∫øm: {e}")
            return []

    def answer_question(self, question):
        """
        Tr·∫£ l·ªùi c√¢u h·ªèi d·ª±a tr√™n vector database, l·ªãch s·ª≠ chat v√† context tr∆∞·ªõc ƒë√≥
        """
        # T√¨m ki·∫øm documents li√™n quan
        docs = self.search_relevant_docs(question)

        if not docs:
            answer = "‚ùå Kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan ƒë·∫øn c√¢u h·ªèi."
            current_context = ""
        else:
            # T·∫°o context t·ª´ c√°c documents hi·ªán t·∫°i
            current_context = "\n\n".join([f"- {doc.page_content}" for doc in docs])

            # T·∫°o prompt v·ªõi l·ªãch s·ª≠ chat v√† context tr∆∞·ªõc ƒë√≥
            prompt = create_qa_prompt(
                current_context,
                question,
                self.chat_history,
                self.context_history
            )

            # G·ªçi Gemini API
            answer = call_gemini_api(prompt, self.api_key)

        # L∆∞u context hi·ªán t·∫°i v√†o l·ªãch s·ª≠ context (ch·ªâ l∆∞u n·∫øu c√≥ context)
        if current_context:
            self.context_history.append(current_context)

            # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng context (ch·ªâ gi·ªØ l·∫°i 2 context g·∫ßn nh·∫•t)
            if len(self.context_history) > self.max_contexts:
                self.context_history.pop(0)  # X√≥a context c≈© nh·∫•t

        # L∆∞u v√†o l·ªãch s·ª≠ chat
        self.chat_history.append((question, answer))

        # Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng l·ªãch s·ª≠ chat
        if len(self.chat_history) > self.max_history:
            self.chat_history.pop(0)  # X√≥a c√¢u h·ªèi c≈© nh·∫•t

        return answer

    def clear_history(self):
        """X√≥a l·ªãch s·ª≠ chat v√† context"""
        self.chat_history.clear()
        self.context_history.clear()
        return "‚úÖ ƒê√£ x√≥a l·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán."

    def show_history(self):
        """Hi·ªÉn th·ªã l·ªãch s·ª≠ chat"""
        if not self.chat_history:
            return "üìù Ch∆∞a c√≥ l·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán."

        history_text = "üìù L·ªäCH S·ª¨ CU·ªòC TR√í CHUY·ªÜN:\n" + "=" * 40 + "\n"
        for i, (q, a) in enumerate(self.chat_history, 1):
            history_text += f"{i}. ‚ùì {q}\n   ü§ñ {a}\n" + "-" * 40 + "\n"
        return history_text

    def show_context_history(self):
        """Hi·ªÉn th·ªã l·ªãch s·ª≠ context t·ª´ vectordb"""
        if not self.context_history:
            return "üìö Ch∆∞a c√≥ context n√†o ƒë∆∞·ª£c l∆∞u."

        context_text = "üìö L·ªäCH S·ª¨ CONTEXT (2 L·∫¶N T√åM KI·∫æM G·∫¶N NH·∫§T):\n" + "=" * 50 + "\n"
        for i, context in enumerate(self.context_history, 1):
            context_text += f"Context {i}:\n{context}\n" + "-" * 50 + "\n"
        return context_text

    def get_system_status(self):
        """Hi·ªÉn th·ªã tr·∫°ng th√°i h·ªá th·ªëng"""
        return f"""üìä TR·∫†NG TH√ÅI H·ªÜ TH·ªêNG:
- S·ªë c√¢u h·ªèi trong l·ªãch s·ª≠: {len(self.chat_history)}/{self.max_history}
- S·ªë context ƒë∆∞·ª£c l∆∞u: {len(self.context_history)}/{self.max_contexts}
- Gi·ªõi h·∫°n context: {self.max_contexts} context g·∫ßn nh·∫•t
- Gi·ªõi h·∫°n l·ªãch s·ª≠ chat: {self.max_history} c√¢u h·ªèi g·∫ßn nh·∫•t"""


# ========== ƒê·ªåC VECTORSTORE FAISS ==========
def load_vector_database():
    """
    Load FAISS vector database
    """
    if not os.path.exists(MOVIE_VECTOR_DB):
        raise FileNotFoundError(f"Th∆∞ m·ª•c vector DB kh√¥ng t·ªìn t·∫°i: {MOVIE_VECTOR_DB}")

    try:
        db = FAISS.load_local(
            MOVIE_VECTOR_DB,
            embedding_wrapper,
            allow_dangerous_deserialization=True
        )
        return db
    except Exception as e:
        raise Exception(f"L·ªói khi load vector database: {e}")


# ========== TEST API CONNECTION ==========
def test_gemini_connection(api_key):
    """
    Test k·∫øt n·ªëi v·ªõi Gemini API
    """
    test_prompt = "Xin ch√†o, b·∫°n c√≥ th·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y kh√¥ng?"
    response = call_gemini_api(test_prompt, api_key)

    if "‚ùå" not in response:
        print("‚úÖ K·∫øt n·ªëi Gemini API th√†nh c√¥ng!")
        return True
    else:
        print(f"‚ùå L·ªói k·∫øt n·ªëi Gemini API: {response}")
        return False


# ========== MAIN PROGRAM ==========
def main():
    print("üé¨ H·ªÜ TH·ªêNG TR·∫¢ L·ªúI C√ÇU H·ªéI V·ªÄ PHIM ·∫¢NH (V·ªõi Context Memory)")
    print("=" * 60)

    # Ki·ªÉm tra API key
    if not GEMINI_API_KEY:
        print("‚ùå Vui l√≤ng ƒë·∫∑t bi·∫øn m√¥i tr∆∞·ªùng GEMINI_API_KEY.")
        print("V√≠ d·ª•: export GEMINI_API_KEY='your_api_key_here'")
        return

    # Test k·∫øt n·ªëi API
    print("üîÑ ƒêang ki·ªÉm tra k·∫øt n·ªëi Gemini API...")
    if not test_gemini_connection(GEMINI_API_KEY):
        return

    # Load vector database
    print("üîÑ ƒêang load vector database...")
    try:
        db = load_vector_database()
        print("‚úÖ Load vector database th√†nh c√¥ng!")
    except Exception as e:
        print(f"‚ùå {e}")
        return

    # Kh·ªüi t·∫°o h·ªá th·ªëng QA
    qa_system = MovieQASystem(db, GEMINI_API_KEY)

    print("\nü§ñ H·ªá th·ªëng ƒë√£ s·∫µn s√†ng! H√£y ƒë·∫∑t c√¢u h·ªèi v·ªÅ phim ·∫£nh.")
    print("üí° L·ªánh ƒë·∫∑c bi·ªát:")
    print("   - 'quit' ho·∫∑c 'exit': Tho√°t ch∆∞∆°ng tr√¨nh")
    print("   - 'history': Xem l·ªãch s·ª≠ chat")
    print("   - 'clear': X√≥a l·ªãch s·ª≠ chat\n")

    # V√≤ng l·∫∑p ch√≠nh
    while True:
        try:
            question = input("‚ùì C√¢u h·ªèi c·ªßa b·∫°n: ").strip()

            if question.lower() in ['quit', 'exit', 'tho√°t']:
                print("üëã C·∫£m ∆°n b·∫°n ƒë√£ s·ª≠ d·ª•ng h·ªá th·ªëng!")
                break

            # L·ªánh xem l·ªãch s·ª≠
            if question.lower() in ['history', 'l·ªãch s·ª≠']:
                print(qa_system.show_history())
                continue

            # L·ªánh x√≥a l·ªãch s·ª≠
            if question.lower() in ['clear', 'x√≥a']:
                print(qa_system.clear_history())
                continue

            if not question:
                print("‚ö†Ô∏è Vui l√≤ng nh·∫≠p c√¢u h·ªèi.")
                continue

            print("üîÑ ƒêang t√¨m ki·∫øm v√† t·∫°o c√¢u tr·∫£ l·ªùi...")

            # Tr·∫£ l·ªùi c√¢u h·ªèi
            answer = qa_system.answer_question(question)

            print(f"\nü§ñ Tr·∫£ l·ªùi:")
            print(f"{answer}")
            print("-" * 50)

        except KeyboardInterrupt:
            print("\nüëã ƒê√£ d·ª´ng ch∆∞∆°ng tr√¨nh.")
            break
        except Exception as e:
            print(f"‚ùå L·ªói: {e}")
            continue


if __name__ == "__main__":
    main()