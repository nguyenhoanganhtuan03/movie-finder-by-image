import os
import requests
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv

from langchain_community.vectorstores import FAISS
from langchain.embeddings.base import Embeddings

# ==== Cáº¤U HÃŒNH ====
load_dotenv()
base_dir = os.path.dirname(os.path.abspath(__file__))
MOVIE_VECTOR_DB = os.path.join(base_dir, "vector_db/movie_vector_db")
EMBEDDING_MODEL = "AITeamVN/Vietnamese_Embedding"

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
GEMINI_API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent"

# ==== LOAD MODEL EMBEDDING ====
model = SentenceTransformer(EMBEDDING_MODEL)
model.max_seq_length = 2048


# ========== WRAPPER EMBEDDING CHO LANGCHAIN ==========
class SentenceTransformerEmbeddingWrapper(Embeddings):
    def __init__(self, model):
        self.model = model

    def embed_documents(self, texts):
        embeddings = self.model.encode(texts, convert_to_numpy=True)
        return embeddings.tolist()

    def embed_query(self, text):
        embedding = self.model.encode([text], convert_to_numpy=True)[0]
        return embedding.tolist()


embedding_wrapper = SentenceTransformerEmbeddingWrapper(model)


# ========== HÃ€M Gá»ŒI GEMINI API ==========
def call_gemini_api(prompt, api_key):
    """
    Gá»i Gemini API Ä‘á»ƒ táº¡o cÃ¢u tráº£ lá»i
    """
    headers = {
        "Content-Type": "application/json"
    }

    data = {
        "contents": [
            {
                "parts": [
                    {"text": prompt}
                ]
            }
        ],
        "generationConfig": {
            "temperature": 0.7,
            "topK": 40,
            "topP": 0.95,
            "maxOutputTokens": 1024,
        }
    }

    try:
        response = requests.post(
            f"{GEMINI_API_URL}?key={api_key}",
            headers=headers,
            json=data,
            timeout=30
        )

        if response.status_code == 200:
            result = response.json()
            if "candidates" in result and len(result["candidates"]) > 0:
                content = result["candidates"][0]["content"]["parts"][0]["text"]
                return content.strip()
            else:
                return "âŒ KhÃ´ng nháº­n Ä‘Æ°á»£c pháº£n há»“i tá»« Gemini API."
        else:
            return f"âŒ Lá»—i API Gemini: {response.status_code} - {response.text}"

    except requests.exceptions.Timeout:
        return "âŒ Timeout khi gá»i Gemini API."
    except requests.exceptions.RequestException as e:
        return f"âŒ Lá»—i káº¿t ná»‘i: {str(e)}"
    except Exception as e:
        return f"âŒ Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {str(e)}"


# ========== Táº O PROMPT TEMPLATE ==========
def create_qa_prompt(context, question, chat_history=None, previous_contexts=None):
    """
    Táº¡o prompt vá»›i lá»‹ch sá»­ chat vÃ  context tá»« cÃ¡c tÃ¬m kiáº¿m trÆ°á»›c
    """
    history_text = ""
    if chat_history:
        history_text = "\nLá»ŠCH Sá»¬ CUá»˜C TRÃ’ CHUYá»†N:\n"
        for i, (q, a) in enumerate(chat_history, 1):
            history_text += f"{i}. Há»i: {q}\n   Tráº£ lá»i: {a}\n"
        history_text += "\n"

    # ThÃªm context tá»« cÃ¡c tÃ¬m kiáº¿m trÆ°á»›c
    previous_context_text = ""
    if previous_contexts:
        previous_context_text = "\nTHÃ”NG TIN Tá»ª CÃC TÃŒM KIáº¾M TRÆ¯á»šC:\n"
        for i, prev_context in enumerate(previous_contexts, 1):
            previous_context_text += f"Context {i}:\n{prev_context}\n\n"

    prompt = f"""Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn tráº£ lá»i cÃ¢u há»i vá» phim áº£nh. Sá»­ dá»¥ng thÃ´ng tin sau Ä‘Ã¢y Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i má»™t cÃ¡ch chÃ­nh xÃ¡c vÃ  ngáº¯n gá»n.

THÃ”NG TIN THAM KHáº¢O CHO CÃ‚U Há»I HIá»†N Táº I:
{context}
{previous_context_text}{history_text}
CÃ‚U Há»I HIá»†N Táº I: {question}

HÆ¯á»šNG DáºªN:
- Æ¯u tiÃªn sá»­ dá»¥ng thÃ´ng tin tá»« "THÃ”NG TIN THAM KHáº¢O CHO CÃ‚U Há»I HIá»†N Táº I"
- CÃ³ thá»ƒ tham kháº£o thÃ´ng tin tá»« cÃ¡c tÃ¬m kiáº¿m trÆ°á»›c vÃ  lá»‹ch sá»­ chat Ä‘á»ƒ hiá»ƒu ngá»¯ cáº£nh tá»‘t hÆ¡n
- Tráº£ lá»i ngáº¯n gá»n, chÃ­nh xÃ¡c
- Náº¿u cÃ¢u há»i khÃ´ng cÃ³ tÃªn phim, Æ°u tiÃªn tÃ¬m phim cÃ³ trong Lá»ŠCH Sá»¬ CUá»˜C TRÃ’ CHUYá»†N
- Náº¿u khÃ´ng tÃ¬m tháº¥y thÃ´ng tin, nÃ³i "TÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin vá» cÃ¢u há»i nÃ y."
- Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t

TRáº¢ Lá»œI:"""

    return prompt

# ========== Äá»ŒC VECTORSTORE FAISS ==========
def load_vector_database():
    """
    Load FAISS vector database
    """
    if not os.path.exists(MOVIE_VECTOR_DB):
        raise FileNotFoundError(f"ThÆ° má»¥c vector DB khÃ´ng tá»“n táº¡i: {MOVIE_VECTOR_DB}")

    try:
        db = FAISS.load_local(
            MOVIE_VECTOR_DB,
            embedding_wrapper,
            allow_dangerous_deserialization=True
        )
        return db
    except Exception as e:
        raise Exception(f"Lá»—i khi load vector database: {e}")

# ========== Há»† THá»NG QA CHÃNH ==========
class MovieQASystem:
    def __init__(self, vector_db=load_vector_database(), api_key=GEMINI_API_KEY, max_history=5, max_contexts=2):
        self.db = vector_db
        self.api_key = api_key
        self.chat_history = []
        self.context_history = []
        self.max_history = max_history
        self.max_contexts = max_contexts

    def search_relevant_docs(self, question, k=3):
        """
        TÃ¬m kiáº¿m cÃ¡c document liÃªn quan Ä‘áº¿n cÃ¢u há»i
        """
        try:
            docs = self.db.similarity_search(question, k=k)
            return docs
        except Exception as e:
            print(f"âŒ Lá»—i khi tÃ¬m kiáº¿m: {e}")
            return []

    def answer_question(self, question):
        """
        Tráº£ lá»i cÃ¢u há»i dá»±a trÃªn vector database, lá»‹ch sá»­ chat vÃ  context trÆ°á»›c Ä‘Ã³
        """
        # TÃ¬m kiáº¿m documents liÃªn quan
        docs = self.search_relevant_docs(question)

        if not docs:
            answer = "âŒ KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan Ä‘áº¿n cÃ¢u há»i."
            current_context = ""
        else:
            # Táº¡o context tá»« cÃ¡c documents hiá»‡n táº¡i
            current_context = "\n\n".join([f"- {doc.page_content}" for doc in docs])

            # Táº¡o prompt vá»›i lá»‹ch sá»­ chat vÃ  context trÆ°á»›c Ä‘Ã³
            prompt = create_qa_prompt(
                current_context,
                question,
                self.chat_history,
                self.context_history
            )

            # Gá»i Gemini API
            answer = call_gemini_api(prompt, self.api_key)

        # LÆ°u context hiá»‡n táº¡i vÃ o lá»‹ch sá»­ context (chá»‰ lÆ°u náº¿u cÃ³ context)
        if current_context:
            self.context_history.append(current_context)

            ## Giá»›i háº¡n sá»‘ lÆ°á»£ng context (chá»‰ giá»¯ láº¡i 2 context gáº§n nháº¥t)
            # if len(self.context_history) > self.max_contexts:
            #     self.context_history.pop(0)  

        # LÆ°u vÃ o lá»‹ch sá»­ chat
        self.chat_history.append((question, answer))

        # Giá»›i háº¡n sá»‘ lÆ°á»£ng lá»‹ch sá»­ chat
        if len(self.chat_history) > self.max_history:
            self.chat_history.pop(0)  

        return answer

# ========== TEST API CONNECTION ==========
def test_gemini_connection(api_key):
    """
    Test káº¿t ná»‘i vá»›i Gemini API
    """
    test_prompt = "Xin chÃ o, báº¡n cÃ³ thá»ƒ tráº£ lá»i cÃ¢u há»i nÃ y khÃ´ng?"
    response = call_gemini_api(test_prompt, api_key)

    if "âŒ" not in response:
        print("âœ… Káº¿t ná»‘i Gemini API thÃ nh cÃ´ng!")
        return True
    else:
        print(f"âŒ Lá»—i káº¿t ná»‘i Gemini API: {response}")
        return False


# ========== MAIN PROGRAM ==========
def main():
    print("ğŸ¬ Há»† THá»NG TRáº¢ Lá»œI CÃ‚U Há»I Vá»€ PHIM áº¢NH (Vá»›i Context Memory)")
    print("=" * 60)

    # Kiá»ƒm tra API key
    if not GEMINI_API_KEY:
        print("âŒ Vui lÃ²ng Ä‘áº·t biáº¿n mÃ´i trÆ°á»ng GEMINI_API_KEY.")
        print("VÃ­ dá»¥: export GEMINI_API_KEY='your_api_key_here'")
        return

    # Test káº¿t ná»‘i API
    print("ğŸ”„ Äang kiá»ƒm tra káº¿t ná»‘i Gemini API...")
    if not test_gemini_connection(GEMINI_API_KEY):
        return

    # Load vector database
    print("ğŸ”„ Äang load vector database...")
    try:
        db = load_vector_database()
        print("âœ… Load vector database thÃ nh cÃ´ng!")
    except Exception as e:
        print(f"âŒ {e}")
        return

    # Khá»Ÿi táº¡o há»‡ thá»‘ng QA
    qa_system = MovieQASystem(db, GEMINI_API_KEY)

    print("\nğŸ¤– Há»‡ thá»‘ng Ä‘Ã£ sáºµn sÃ ng! HÃ£y Ä‘áº·t cÃ¢u há»i vá» phim áº£nh.")
    print("   - 'quit' hoáº·c 'exit': ThoÃ¡t chÆ°Æ¡ng trÃ¬nh")

    # VÃ²ng láº·p chÃ­nh
    while True:
        try:
            question = input("â“ CÃ¢u há»i cá»§a báº¡n: ").strip()

            if question.lower() in ['quit', 'exit', 'thoÃ¡t']:
                print("ğŸ‘‹ Cáº£m Æ¡n báº¡n Ä‘Ã£ sá»­ dá»¥ng há»‡ thá»‘ng!")
                break

            if not question:
                print("âš ï¸ Vui lÃ²ng nháº­p cÃ¢u há»i.")
                continue

            print("ğŸ”„ Äang tÃ¬m kiáº¿m vÃ  táº¡o cÃ¢u tráº£ lá»i...")

            # Tráº£ lá»i cÃ¢u há»i
            answer = qa_system.answer_question(question)

            print(f"\nğŸ¤– Tráº£ lá»i:")
            print(f"{answer}")
            print("-" * 50)

        except KeyboardInterrupt:
            print("\nğŸ‘‹ ÄÃ£ dá»«ng chÆ°Æ¡ng trÃ¬nh.")
            break
        except Exception as e:
            print(f"âŒ Lá»—i: {e}")
            continue


# if __name__ == "__main__":
#     main()