import os
import requests
from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv

from langchain_community.vectorstores import FAISS
from langchain.embeddings.base import Embeddings
from langchain.prompts import PromptTemplate
from langchain.schema import HumanMessage, AIMessage


# ==== C·∫§U H√åNH ====
load_dotenv()
base_dir = os.path.dirname(os.path.abspath(__file__))
MOVIE_VECTOR_DB = os.path.join(base_dir, "vector_db/movie_vector_db")
EMBEDDING_MODEL = "AITeamVN/Vietnamese_Embedding"
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY_3")
GEMINI_API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent"

# ==== LOAD MODEL EMBEDDING ====
model = SentenceTransformer(EMBEDDING_MODEL)
model.max_seq_length = 2048

# ==== WRAPPER EMBEDDING CHO LANGCHAIN ====
class SentenceTransformerEmbeddingWrapper(Embeddings):
    def __init__(self, model):
        self.model = model

    def embed_documents(self, texts):
        embeddings = self.model.encode(texts, convert_to_numpy=True)
        return embeddings.tolist()

    def embed_query(self, text):
        embedding = self.model.encode([text], convert_to_numpy=True)[0]
        return embedding.tolist()

embedding_wrapper = SentenceTransformerEmbeddingWrapper(model)


# ==== H√ÄM G·ªåI GEMINI API (c√≥ duy tr√¨ l·ªãch s·ª≠) ====
def call_gemini_api_with_history(message_history, api_key):
    headers = {"Content-Type": "application/json"}
    data = {
        "contents": message_history,
        "generationConfig": {
            "temperature": 0.7,
            "topK": 10,
            "topP": 0.95,
            "maxOutputTokens": 2048,
        }
    }
    try:
        response = requests.post(
            f"{GEMINI_API_URL}?key={api_key}",
            headers=headers,
            json=data,
            timeout=30
        )
        if response.status_code == 200:
            result = response.json()
            candidates = result.get("candidates", [])
            if candidates:
                return candidates[0]["content"]["parts"][0]["text"].strip()
            return "‚ùå Kh√¥ng nh·∫≠n ƒë∆∞·ª£c ph·∫£n h·ªìi t·ª´ Gemini API."
        return f"‚ùå L·ªói API Gemini: {response.status_code} - {response.text}"
    except Exception as e:
        return f"‚ùå L·ªói khi g·ªçi Gemini: {str(e)}"


# ==== PROMPT KH·ªûI T·∫†O ====
def create_qa_prompt():
    return (
        "B·∫°n l√† m·ªôt chuy√™n gia ƒëi·ªán ·∫£nh. Tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng v·ªÅ c√°c b·ªô phim, "
        "di·ªÖn vi√™n, ƒë·∫°o di·ªÖn, th·ªÉ lo·∫°i ho·∫∑c nƒÉm ph√°t h√†nh m·ªôt c√°ch ch√≠nh x√°c v√† d·ªÖ hi·ªÉu. "
        "H√£y duy tr√¨ ng·ªØ c·∫£nh c·ªßa cu·ªôc tr√≤ chuy·ªán v√† tham kh·∫£o c√°c c√¢u h·ªèi tr∆∞·ªõc ƒë√≥ khi c·∫ßn thi·∫øt. "
        "N·∫øu ng∆∞·ªùi d√πng h·ªèi v·ªÅ 'phim n√†y', 'b·ªô phim ƒë√≥', 'phim v·ª´a n√≥i', h√£y hi·ªÉu h·ªç ƒëang nh·∫Øc ƒë·∫øn phim ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p g·∫ßn nh·∫•t."
    )


# ==== H·ªÜ TH·ªêNG QA ====
class MovieQASystem:
    def __init__(self, vector_db=None, api_key=None, max_history=20):
        self.db = vector_db or load_vector_database()
        self.api_key = api_key or GEMINI_API_KEY
        self.max_history = max_history

        # Kh·ªüi t·∫°o l·ªãch s·ª≠ v·ªõi system prompt
        self.message_history = [
            {"role": "user", "parts": [{"text": create_qa_prompt()}]},
            {"role": "model", "parts": [{
                                            "text": "Ch√†o b·∫°n! T√¥i l√† chuy√™n gia ƒëi·ªán ·∫£nh. T√¥i s·∫Ω tr·∫£ l·ªùi c√°c c√¢u h·ªèi v·ªÅ phim v√† duy tr√¨ ng·ªØ c·∫£nh cu·ªôc tr√≤ chuy·ªán. H√£y h·ªèi t√¥i b·∫•t k·ª≥ ƒëi·ªÅu g√¨ v·ªÅ phim nh√©!"}]}
        ]

        self.last_used_docs = []
        self.current_movie_context = None  # L∆∞u phim ƒëang ƒë∆∞·ª£c th·∫£o lu·∫≠n

    def search_relevant_docs(self, query, k=10):
        try:
            return self.db.similarity_search(query, k=k)
        except Exception as e:
            print(f"‚ùå L·ªói khi t√¨m ki·∫øm: {e}")
            return []

    def update_history(self, role, text):
        """C·∫≠p nh·∫≠t l·ªãch s·ª≠ tr√≤ chuy·ªán"""
        self.message_history.append({"role": role, "parts": [{"text": text}]})

        # Gi·ªØ l·∫°i system prompt v√† gi·ªõi h·∫°n l·ªãch s·ª≠
        if len(self.message_history) > self.max_history + 2:  # +2 cho system prompt v√† response
            # Gi·ªØ l·∫°i system prompt (2 message ƒë·∫ßu) v√† c√°c message g·∫ßn nh·∫•t
            system_messages = self.message_history[:2]
            recent_messages = self.message_history[-(self.max_history):]
            self.message_history = system_messages + recent_messages

    def extract_movie_from_response(self, response):
        """Tr√≠ch xu·∫•t t√™n phim t·ª´ c√¢u tr·∫£ l·ªùi ƒë·ªÉ l∆∞u context"""
        # T√¨m ki·∫øm pattern phim trong c√¢u tr·∫£ l·ªùi
        import re
        movie_patterns = [
            r'[Pp]him\s+["\*]?([^"\*\n]+)["\*]?',
            r'[Bb]·ªô phim\s+["\*]?([^"\*\n]+)["\*]?',
            r'[Tt]√°c ph·∫©m\s+["\*]?([^"\*\n]+)["\*]?'
        ]

        for pattern in movie_patterns:
            matches = re.findall(pattern, response)
            if matches:
                return matches[0].strip()
        return None

    def build_context_aware_prompt(self, question, docs):
        """T·∫°o prompt c√≥ nh·∫≠n th·ª©c v·ªÅ ng·ªØ c·∫£nh"""
        context_parts = []

        # Th√™m th√¥ng tin t·ª´ vector database
        if docs:
            doc_context = "\n".join(f"- {doc.page_content}" for doc in docs)
            context_parts.append(f"TH√îNG TIN THAM KH·∫¢O:\n{doc_context}")

        # Th√™m ng·ªØ c·∫£nh phim hi·ªán t·∫°i n·∫øu c√≥
        if self.current_movie_context:
            context_parts.append(f"PHIM ƒêANG TH·∫¢O LU·∫¨N: {self.current_movie_context}")

        # Th√™m l·ªùi nh·∫Øc v·ªÅ ng·ªØ c·∫£nh
        context_parts.append(
            "L∆ØU √ù: H√£y tham kh·∫£o c√°c c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi tr∆∞·ªõc ƒë√≥ trong cu·ªôc tr√≤ chuy·ªán ƒë·ªÉ hi·ªÉu ƒë√∫ng ng·ªØ c·∫£nh.")

        if context_parts:
            full_context = "\n\n".join(context_parts)
            return f"{full_context}\n\nC√ÇU H·ªéI: {question}"
        else:
            return f"C√ÇU H·ªéI: {question}"

    def is_context_dependent_question(self, question):
        """Ki·ªÉm tra xem c√¢u h·ªèi c√≥ ph·ª• thu·ªôc v√†o ng·ªØ c·∫£nh kh√¥ng"""
        context_indicators = [
            'phim n√†y', 'phim ƒë√≥', 'phim v·ª´a n√≥i', 'b·ªô phim n√†y', 'b·ªô phim ƒë√≥',
            'phim tr√™n', 'phim n√≥i ·ªü tr√™n', 'c√≥ nh·ªØng ai', 'di·ªÖn vi√™n n√†o',
            'khi n√†o', 'nƒÉm n√†o', 'th·ªÉ lo·∫°i g√¨', 'ƒë·∫°o di·ªÖn n√†o'
        ]

        question_lower = question.lower()
        return any(indicator in question_lower for indicator in context_indicators)

    def answer_question(self, question):
        """Tr·∫£ l·ªùi c√¢u h·ªèi v·ªõi duy tr√¨ ng·ªØ c·∫£nh"""
        # T√¨m ki·∫øm documents li√™n quan
        docs = self.search_relevant_docs(question)

        # N·∫øu kh√¥ng t√¨m th·∫•y doc m·ªõi v√† c√¢u h·ªèi ph·ª• thu·ªôc ng·ªØ c·∫£nh, d√πng doc c≈©
        if not docs and self.is_context_dependent_question(question):
            docs = self.last_used_docs

        # C·∫≠p nh·∫≠t doc ƒë∆∞·ª£c s·ª≠ d·ª•ng
        if docs:
            self.last_used_docs = docs

        # T·∫°o prompt c√≥ nh·∫≠n th·ª©c ng·ªØ c·∫£nh
        prompt = self.build_context_aware_prompt(question, docs)

        # Th√™m c√¢u h·ªèi v√†o l·ªãch s·ª≠
        self.update_history("user", prompt)

        # G·ªçi API
        response = call_gemini_api_with_history(self.message_history, self.api_key)

        # C·∫≠p nh·∫≠t ng·ªØ c·∫£nh phim hi·ªán t·∫°i
        movie_mentioned = self.extract_movie_from_response(response)
        if movie_mentioned:
            self.current_movie_context = movie_mentioned

        # Th√™m c√¢u tr·∫£ l·ªùi v√†o l·ªãch s·ª≠
        self.update_history("model", response)

        return response

    def get_conversation_history(self):
        """L·∫•y l·ªãch s·ª≠ tr√≤ chuy·ªán cho debug"""
        return self.message_history[2:]  # B·ªè qua system prompt

    def clear_history(self):
        """X√≥a l·ªãch s·ª≠ tr√≤ chuy·ªán"""
        self.message_history = [
            {"role": "user", "parts": [{"text": create_qa_prompt()}]},
            {"role": "model", "parts": [{"text": "Ch√†o b·∫°n! T√¥i l√† chuy√™n gia ƒëi·ªán ·∫£nh. T√¥i s·∫Ω tr·∫£ l·ªùi c√°c c√¢u h·ªèi v·ªÅ phim v√† duy tr√¨ ng·ªØ c·∫£nh cu·ªôc tr√≤ chuy·ªán. H√£y h·ªèi t√¥i b·∫•t k·ª≥ ƒëi·ªÅu g√¨ v·ªÅ phim nh√©!"}]}
        ]
        self.current_movie_context = None
        self.last_used_docs = []

# ========== ƒê·ªåC VECTORSTORE FAISS ==========
def load_vector_database():
    if not os.path.exists(MOVIE_VECTOR_DB):
        raise FileNotFoundError(f"Th∆∞ m·ª•c vector DB kh√¥ng t·ªìn t·∫°i: {MOVIE_VECTOR_DB}")
    try:
        db = FAISS.load_local(
            MOVIE_VECTOR_DB,
            embedding_wrapper,
            allow_dangerous_deserialization=True
        )
        return db
    except Exception as e:
        raise Exception(f"L·ªói khi load vector database: {e}")

# ========== MAIN PROGRAM ==========
def main():
    print("\U0001f3ac H·ªÜ TH·ªêNG TR·∫¢ L·ªúI C√ÇU H·ªéI V·ªÄ PHIM ·∫¢NH (V·ªõi Context Memory)")
    print("=" * 60)
    if not GEMINI_API_KEY:
        print("‚ùå Vui l√≤ng ƒë·∫∑t bi·∫øn m√¥i tr∆∞·ªùng GEMINI_API_KEY.")
        return
    print("üîÑ ƒêang load vector database...")
    try:
        db = load_vector_database()
        print("‚úÖ Load vector database th√†nh c√¥ng!")
    except Exception as e:
        print(f"‚ùå {e}")
        return
    qa_system = MovieQASystem(db, GEMINI_API_KEY)
    print("\nü§ñ H·ªá th·ªëng ƒë√£ s·∫µn s√†ng! H√£y ƒë·∫∑t c√¢u h·ªèi v·ªÅ phim ·∫£nh.")
    print("   - 'quit' ho·∫∑c 'exit': Tho√°t ch∆∞∆°ng tr√¨nh")
    while True:
        try:
            question = input("‚ùì C√¢u h·ªèi c·ªßa b·∫°n: ").strip()
            if question.lower() in ['quit', 'exit', 'tho√°t']:
                print("üëã C·∫£m ∆°n b·∫°n ƒë√£ s·ª≠ d·ª•ng h·ªá th·ªëng!")
                break
            if not question:
                print("‚ö†Ô∏è Vui l√≤ng nh·∫≠p c√¢u h·ªèi.")
                continue
            print("üîÑ ƒêang t√¨m ki·∫øm v√† t·∫°o c√¢u tr·∫£ l·ªùi...")
            answer = qa_system.answer_question(question)
            print(f"\nü§ñ Tr·∫£ l·ªùi:")
            print(f"{answer}")
            print("-" * 50)
        except KeyboardInterrupt:
            print("\nüëã ƒê√£ d·ª´ng ch∆∞∆°ng tr√¨nh.")
            break
        except Exception as e:
            print(f"‚ùå L·ªói: {e}")
            continue

if __name__ == "__main__":
    main()
